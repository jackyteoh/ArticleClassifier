{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import os\n",
    "import re\n",
    "os.chdir(\"./Desktop/ArticleClassifier\")\n",
    "\n",
    "# Changing the kernels being used and the c values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through 70% of the text files from each category (folder)\n",
    "# 70% Training, 30% Testing for each category\n",
    "#Creates training_titles and testing_tiles\n",
    "training_titles_files = []\n",
    "testing_titles_files = [] \n",
    "\n",
    "business_files = os.listdir(\"./business\")\n",
    "train_business = business_files[0:358]\n",
    "test_business = business_files[358:] # length = 152, TOTAL = 510 \n",
    "training_titles_files.append(train_business)\n",
    "testing_titles_files.append(test_business)\n",
    "\n",
    "entertainment_files = os.listdir(\"./entertainment\")\n",
    "train_entertainment = entertainment_files[0:270]\n",
    "test_entertainment = entertainment_files[270:] # 116, TOTAL = 386\n",
    "training_titles_files.append(train_entertainment)\n",
    "testing_titles_files.append(test_entertainment)\n",
    "\n",
    "politics_files = os.listdir(\"./politics\")\n",
    "train_politics = politics_files[0:293]\n",
    "test_politics = politics_files[293:] # 124, TOTAL = 417\n",
    "training_titles_files.append(train_politics)\n",
    "testing_titles_files.append(test_politics)\n",
    "\n",
    "sport_files = os.listdir(\"./sport\")\n",
    "train_sport = sport_files[0:359]\n",
    "test_sport = sport_files[359:] # 152, TOTAL = 511\n",
    "training_titles_files.append(train_sport)\n",
    "testing_titles_files.append(test_sport)\n",
    "\n",
    "tech_files = os.listdir(\"./tech\")\n",
    "train_tech = tech_files[0:281]\n",
    "test_tech = tech_files[281:] # 120, TOTAL = 401\n",
    "training_titles_files.append(train_tech)\n",
    "testing_titles_files.append(test_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text_file = open(\"trainingTextFile.txt\", \"w\")\n",
    "\n",
    "classes = 1\n",
    "for i in training_titles_files:\n",
    "\tfolder_name = \"\"\n",
    "\tif (classes == 1): \n",
    "\t\tfolder_name = \"business\"\n",
    "\telif (classes == 2):\n",
    "\t\tfolder_name = \"entertainment\"\n",
    "\telif (classes == 3):\n",
    "\t\tfolder_name = \"politics\"\n",
    "\telif (classes == 4):\n",
    "\t\tfolder_name = \"sport\"\n",
    "\telif (classes == 5):\n",
    "\t\tfolder_name = \"tech\"\n",
    "\tfor file_name in i:\n",
    "\t\tfile = \"./\" + folder_name + \"/\" + file_name\n",
    "\t\t#print(file)\n",
    "\t\topened = open(file, \"r\")\n",
    "\t\ttraining_text_file.write(opened.readline())\n",
    "\t\topened.close()\n",
    "\tclasses = classes + 1\n",
    "\n",
    "training_text_file.close()\n",
    "\n",
    "masterTestDataFile = open(\"testTextFile.txt\", \"w\")\n",
    "\n",
    "classes = 1\n",
    "for i in testing_titles_files:\n",
    "\tfolder_name = \"\"\n",
    "\tif (classes == 1): \n",
    "\t\tfolder_name = \"business\"\n",
    "\telif (classes == 2):\n",
    "\t\tfolder_name = \"entertainment\"\n",
    "\telif (classes == 3):\n",
    "\t\tfolder_name = \"politics\"\n",
    "\telif (classes == 4):\n",
    "\t\tfolder_name = \"sport\"\n",
    "\telif (classes == 5):\n",
    "\t\tfolder_name = \"tech\"\n",
    "\tfor file_name in i:\n",
    "\t\tfile = \"./\" + folder_name + \"/\" + file_name\n",
    "\t\t#print (file)\n",
    "\t\topened = open(file, \"r\")\n",
    "\t\tlineRead = opened.readline()\n",
    "\t\t#try: \n",
    "\t\tmasterTestDataFile.write(lineRead)\n",
    "\t\t#except UnicodeDecodeError:\n",
    "\t\topened.close()\n",
    "\tclasses = classes + 1\n",
    "\n",
    "masterTestDataFile.close()\n",
    "\n",
    "#currency stemming nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "testing = []\n",
    "\n",
    "# Puts words in dictionary, key = word, value = index\n",
    "trfile = open(\"trainingTextFile.txt\", \"r\")\n",
    "\n",
    "for line in trfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tnew_line = line.split()\n",
    "\tfor i in new_line:\n",
    "\t\ttraining.append(i)\n",
    "\n",
    "trfile.close()\n",
    "\n",
    "words = {}\n",
    "count = 0\n",
    "for i in training:\n",
    "\tif i not in words:\n",
    "\t\twords[i] = count\n",
    "\t\tcount = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Training Data Matrix\n",
    "d = len(words) # Number of features (unique words) we have in the dictionary\n",
    "# print(d)\n",
    "train_x = []\n",
    "\n",
    "trfile = open(\"trainingTextFile.txt\", \"r\")\n",
    "\n",
    "for line in trfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tword = line.split()\n",
    "\tarr = [0] * d\n",
    "\tfor i in word:\n",
    "\t\tindex = words[i]\n",
    "\t\tarr[index] = arr[index] + 1\n",
    "\ttrain_x.append(arr)\n",
    "trfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "#Target Training Vector\n",
    "train_y = np.zeros((1561, 1))\n",
    "for i in range(0, 1561):\n",
    "    if i >=0 and i < 358:\n",
    "        train_y[i] = 1\n",
    "    elif i >= 358 and i < 628:\n",
    "        train_y[i] = 2\n",
    "    elif i >= 628 and i < 921:\n",
    "        train_y[i] = 3\n",
    "    elif i >= 921 and i < 1280:\n",
    "        train_y[i] = 4\n",
    "    elif i >= 1280 and i < 1561:\n",
    "        train_y[i] = 5\n",
    "print(train_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Testing Data Matrix\n",
    "test_x = []\n",
    "\n",
    "testfile = open(\"testTextFile.txt\", \"r\")\n",
    "\n",
    "for line in testfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tword = line.split()\n",
    "\tarr = [0] * d\n",
    "\tfor i in word:\n",
    "\t\tif i in words:\n",
    "\t\t\tindex = words[i]\n",
    "\t\t\tarr[index] = arr[index] + 1\n",
    "\ttest_x.append(arr)\n",
    "\n",
    "testfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 1)\n"
     ]
    }
   ],
   "source": [
    "#Target Test Vector\n",
    "test_y = np.zeros((664, 1))\n",
    "for i in range(0, 664):\n",
    "    if i >= 0 and i < 152:\n",
    "        test_y[i] = 1\n",
    "    elif i >= 152 and i < 268:\n",
    "        test_y[i] = 2\n",
    "    elif i >= 268 and i < 392:\n",
    "        test_y[i] = 3\n",
    "    elif i >= 392 and i < 544:\n",
    "        test_y[i] = 4\n",
    "    elif i >= 544 and i < 664:\n",
    "        test_y[i] = 5\n",
    "    else:\n",
    "        test_y[i] = 1\n",
    "\n",
    "# countzero = 0\n",
    "# countone = 0\n",
    "# counttwo = 0\n",
    "# countthree = 0\n",
    "# countfour = 0\n",
    "# for i in test_y:\n",
    "# \tif i == 0:\n",
    "# \t\tcountzero+=1\n",
    "# \tif i == 1:\n",
    "# \t\tcountone += 1\n",
    "# \tif i == 2:\n",
    "# \t\tcounttwo+=1 \n",
    "# \tif i == 3:\n",
    "# \t\tcountthree+=1\n",
    "# \tif i == 4:\n",
    "# \t\tcountfour +=1\n",
    "\n",
    "#print(countzero)\n",
    "#print(countone)\n",
    "#print(counttwo)\n",
    "#print(countthree)\n",
    "#print(countfour)\n",
    "\n",
    "\n",
    "# y = 0 --> Business\n",
    "# y = 1 --> Entertainment\n",
    "# y = 2 --> Politics\n",
    "# y = 3 --> Sport\n",
    "# y = 4 --> Tech\n",
    "\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using the Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training for each classification\n",
    "train_y_1 = train_y.copy()\n",
    "train_y_2 = train_y.copy()\n",
    "train_y_3 = train_y.copy()\n",
    "train_y_4 = train_y.copy()\n",
    "train_y_5 = train_y.copy()\n",
    "\n",
    "# Changing the values that aren't the classified values to 0\n",
    "train_y_1[train_y_1 != 1] = 0\n",
    "train_y_2[train_y_2 != 2] = 0\n",
    "train_y_3[train_y_3 != 3] = 0\n",
    "train_y_4[train_y_4 != 4] = 0\n",
    "train_y_5[train_y_5 != 5] = 0\n",
    "\n",
    "# Changes the correct classification values to 1 so it's easier\n",
    "train_y_2[train_y_2 == 2] = 1\n",
    "train_y_3[train_y_3 == 3] = 1\n",
    "train_y_4[train_y_4 == 4] = 1\n",
    "train_y_5[train_y_5 == 5] = 1\n",
    "\n",
    "train_y_1_arr = []\n",
    "train_y_2_arr = []\n",
    "train_y_3_arr = []\n",
    "train_y_4_arr = []\n",
    "train_y_5_arr = []\n",
    "\n",
    "for i in range(0, 1561):\n",
    "    train_y_1_arr.insert(i, int(train_y_1[i][0]))\n",
    "    train_y_2_arr.insert(i, int(train_y_2[i][0]))\n",
    "    train_y_3_arr.insert(i, int(train_y_3[i][0]))\n",
    "    train_y_4_arr.insert(i, int(train_y_4[i][0]))\n",
    "    train_y_5_arr.insert(i, int(train_y_5[i][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear(c, X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    # TODO - Create an object of svm.SVC(probability = False, kernel = 'linear', C = c) - 5 points\n",
    "    svc_linear = svm.SVC(probability = True, kernel = 'linear', C = c)\n",
    "    \n",
    "    # TODO - Fit the classifier on the training set - 5 points\n",
    "    svc_linear.fit(X_train, Y_train)\n",
    "    \n",
    "    # TODO - Find the prediction and accuracy on the test set - 5 points\n",
    "    Yhat_svc_linear_test = svc_linear.predict(X_test)\n",
    "    \n",
    "    prob.append(svc_linear.predict_proba(X_test))\n",
    "    #print(svc_linear.predict_proba(X_test)[0][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the above function i.e. svm_linear with different values of parameter 'c'.\n",
    "# Start with smaller values of 'c' say 0.0001, 0.001, 0.01, 0.1, 1, 10, 100\n",
    "#cVals = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "c = 1\n",
    "svm_linear(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "svm_linear(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "svm_linear(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "svm_linear(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "svm_linear(c, train_x, train_y_5_arr, test_x, test_y_5_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 5, 3, 1, 4, 1, 1, 5, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 5, 1, 2, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 5, 3, 1, 3, 4, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 4, 1, 3, 4, 4, 1, 1, 1, 1, 5, 1, 3, 1, 1, 1, 4, 1, 3, 5, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 5, 1, 1, 1, 5, 1, 1, 3, 4, 1, 1, 4, 1, 1, 2, 3, 2, 5, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 5, 4, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 4, 2, 2, 2, 4, 4, 1, 3, 1, 2, 2, 2, 2, 2, 2, 3, 5, 2, 4, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 5, 2, 1, 2, 2, 3, 2, 2, 4, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 3, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 3, 5, 3, 4, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 4, 3, 5, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 1, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 3, 4, 4, 1, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 1, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 3, 5, 4, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 4, 5, 5, 1, 5, 5, 5, 3, 5, 5, 1, 5, 5, 5, 2, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 2, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 2, 5, 5, 2, 5, 1, 1, 5, 5, 1, 5, 1, 5, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "test_yhat_linear = []\n",
    "# test_yhat_linear_pac = []\n",
    "for i in range (0, len(test_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    #max_prob = max(m1, m2, m3, m4, m5)\n",
    "    \n",
    "#     probability_and_classification.append(max(values))\n",
    "#     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "#     test_yhat_linear_pac.append(probability_and_classification)\n",
    "    \n",
    "    test_yhat_linear.append((values.index(max(values))) + 1)\n",
    "print(test_yhat_linear) # Correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7756024096385542 is the testing accuracy for our SVM with linear kernel\n"
     ]
    }
   ],
   "source": [
    "#Calculate testing accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, 664):\n",
    "    if (test_yhat_linear[i] == test_y[i]):\n",
    "        correct+= 1\n",
    "#         print(test_yhat_linear[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", test_yhat_linear[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "test_acc_linear = correct/len(test_x)\n",
    "print(test_acc_linear, \"is the testing accuracy for our SVM with linear kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "1.0 is the training accuracy for our SVM with linear kernel\n"
     ]
    }
   ],
   "source": [
    "#training accuracy\n",
    "\n",
    "c = 1\n",
    "prob = []\n",
    "svm_linear(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "svm_linear(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "svm_linear(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "svm_linear(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "svm_linear(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "train_yhat_linear = []\n",
    "for i in range (0, len(train_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    \n",
    "    train_yhat_linear.append((values.index(max(values))) + 1)\n",
    "print(train_yhat_linear) # Correct\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(train_x)):\n",
    "    if (train_yhat_linear[i] == train_y[i]):\n",
    "        correct+= 1\n",
    "#         print(train_yhat_linear[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", train_yhat_linear[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "train_acc_linear = correct/len(train_x)\n",
    "print(train_acc_linear, \"is the training accuracy for our SVM with linear kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using the Radial Basis Function (RBF) Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "def svm_rbf(c, X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    # TODO - Create an object of svm.SVC(probability = False, kernel = 'rbf', C = c) - 5 points\n",
    "    svc_rbf = svm.SVC(probability = True, kernel = 'rbf', C = c)\n",
    "    \n",
    "    # TODO - Fit the classifier on the training set - 5 points\n",
    "    svc_rbf.fit(X_train, Y_train)\n",
    "    \n",
    "    # TODO - Find the prediction and accuracy on the test set - 5 points\n",
    "    Yhat_svc_rbf_test = svc_rbf.predict(X_test)\n",
    "    \n",
    "    prob.append(svc_rbf.predict_proba(X_test))\n",
    "    #print(svc_rbf.predict_proba(X_test)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 1, 4, 2, 3, 1, 4, 1, 1, 5, 1, 1, 1, 1, 1, 3, 1, 3, 4, 3, 1, 3, 1, 1, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 5, 3, 4, 1, 1, 1, 4, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 5, 1, 1, 4, 1, 3, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 2, 1, 1, 1, 1, 3, 1, 4, 4, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 4, 1, 3, 4, 4, 1, 1, 1, 1, 5, 1, 3, 1, 1, 1, 1, 1, 4, 4, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 5, 1, 1, 1, 1, 1, 1, 3, 4, 1, 1, 4, 1, 1, 5, 3, 2, 5, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 5, 2, 1, 4, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 4, 4, 2, 3, 2, 4, 4, 1, 3, 1, 2, 2, 2, 4, 2, 5, 3, 5, 2, 2, 2, 2, 2, 2, 2, 4, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 3, 3, 5, 3, 5, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 4, 3, 3, 3, 3, 2, 3, 4, 4, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 5, 3, 3, 4, 5, 3, 5, 3, 3, 3, 3, 3, 3, 1, 3, 4, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 5, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 4, 3, 3, 3, 4, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 1, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 2, 4, 4, 3, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 3, 5, 4, 4, 5, 4, 5, 5, 5, 5, 5, 5, 2, 5, 5, 2, 4, 5, 5, 1, 5, 5, 1, 3, 5, 5, 1, 5, 5, 5, 4, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 2, 2, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 4, 5, 1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 4, 5, 5, 5, 5, 2, 5, 2, 1, 5, 2, 5, 4, 1, 5, 5, 1, 5, 1, 5, 5, 4]\n",
      "0.7545180722891566 is the testing accuracy for our SVM with rbf kernel\n"
     ]
    }
   ],
   "source": [
    "#Testing Accuracy\n",
    "c = 1\n",
    "svm_rbf(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "svm_rbf(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "svm_rbf(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "svm_rbf(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "svm_rbf(c, train_x, train_y_5_arr, test_x, test_y_5_arr)\n",
    "\n",
    "test_yhat_rbf = []\n",
    "# test_yhat_rbf_pac = []\n",
    "for i in range (0, len(test_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    #max_prob = max(m1, m2, m3, m4, m5)\n",
    "    \n",
    "#     probability_and_classification.append(max(values))\n",
    "#     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "#     test_yhat_rbf_pac.append(probability_and_classification)\n",
    "    \n",
    "    test_yhat_rbf.append((values.index(max(values))) + 1)\n",
    "print(test_yhat_rbf) # Correct\n",
    "\n",
    "#Calculate testing accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(test_x)):\n",
    "    if (test_yhat_rbf[i] == test_y[i]):\n",
    "        correct+= 1\n",
    "#         print(test_yhat_rbf[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", test_yhat_rbf[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "test_acc_rbf = correct/len(test_x)\n",
    "print(test_acc_rbf, \"is the testing accuracy for our SVM with rbf kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "0.9801409352978859 is the training accuracy for our SVM with rbf kernel\n"
     ]
    }
   ],
   "source": [
    "#training accuracy\n",
    "\n",
    "c = 1\n",
    "prob = []\n",
    "svm_rbf(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "svm_rbf(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "svm_rbf(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "svm_rbf(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "svm_rbf(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "train_yhat_rbf = []\n",
    "for i in range (0, len(train_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    \n",
    "    train_yhat_rbf.append((values.index(max(values))) + 1)\n",
    "print(train_yhat_rbf) # Correct\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(train_x)):\n",
    "    if (train_yhat_rbf[i] == train_y[i]):\n",
    "        correct+= 1\n",
    "#         print(train_yhat_rbf[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", train_yhat_rbf[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "train_acc_rbf = correct/len(train_x)\n",
    "print(train_acc_rbf, \"is the training accuracy for our SVM with rbf kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using the Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "def svm_poly(c, X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    # TODO - Create an object of svm.SVC(probability = False, kernel = 'poly', C = c) - 5 points\n",
    "    svc_poly = svm.SVC(probability = True, kernel = 'poly', C = c)\n",
    "    \n",
    "    # TODO - Fit the classifier on the training set - 5 points\n",
    "    svc_poly.fit(X_train, Y_train)\n",
    "    \n",
    "    # TODO - Find the prediction and accuracy on the test set - 5 points\n",
    "    Yhat_svc_poly_test = svc_poly.predict(X_test)\n",
    "    \n",
    "    prob.append(svc_poly.predict_proba(X_test))\n",
    "    #print(svc_poly.predict_proba(X_test)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 4, 4, 1, 4, 1, 4, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 4, 1, 1, 4, 4, 1, 1, 1, 1, 4, 1, 4, 4, 1, 1, 4, 1, 1, 1, 1, 4, 4, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 4, 4, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 4, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 4, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 4, 4, 1, 1, 1, 4, 1, 4, 1, 1, 1, 4, 4, 4, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4, 4, 4, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 4, 4, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 4, 4, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 4, 4, 1, 1, 1, 1, 1, 4, 4, 1, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 4, 1, 1, 1, 1, 4, 4, 1, 1, 4, 1, 1, 4, 4, 1, 1, 1, 1, 4, 4, 4, 1, 4, 4, 1, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0.28012048192771083 is the testing accuracy for our SVM with poly kernel\n"
     ]
    }
   ],
   "source": [
    "#Testing Accuracy\n",
    "c = 1\n",
    "svm_poly(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "svm_poly(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "svm_poly(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "svm_poly(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "svm_poly(c, train_x, train_y_5_arr, test_x, test_y_5_arr)\n",
    "\n",
    "test_yhat_poly = []\n",
    "# test_yhat_poly_pac = []\n",
    "for i in range (0, len(test_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    #max_prob = max(m1, m2, m3, m4, m5)\n",
    "    \n",
    "#     probability_and_classification.append(max(values))\n",
    "#     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "#     test_yhat_poly_pac.append(probability_and_classification)\n",
    "    \n",
    "    test_yhat_poly.append((values.index(max(values))) + 1)\n",
    "print(test_yhat_poly) # Correct\n",
    "\n",
    "#Calculate testing accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(test_x)):\n",
    "    if (test_yhat_poly[i] == test_y[i]):\n",
    "        correct+= 1\n",
    "#         print(test_yhat_poly[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", test_yhat_poly[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "test_acc_poly = correct/len(test_x)\n",
    "print(test_acc_poly, \"is the testing accuracy for our SVM with poly kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 4, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 4, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4, 1, 4, 1, 1, 4, 1]\n",
      "0.2453555413196669 is the training accuracy for our SVM with poly kernel\n"
     ]
    }
   ],
   "source": [
    "#training accuracy\n",
    "\n",
    "c = 1\n",
    "prob = []\n",
    "svm_poly(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "svm_poly(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "svm_poly(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "svm_poly(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "svm_poly(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "train_yhat_poly = []\n",
    "for i in range (0, len(train_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    \n",
    "    train_yhat_poly.append((values.index(max(values))) + 1)\n",
    "print(train_yhat_poly) # Correct\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(train_x)):\n",
    "    if (train_yhat_poly[i] == train_y[i]):\n",
    "        correct+= 1\n",
    "#         print(train_yhat_poly[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", train_yhat_poly[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "train_acc_poly = correct/len(train_x)\n",
    "print(train_acc_poly, \"is the training accuracy for our SVM with poly kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for linear is:  0.7756024096385542\n",
      "Training accuracy for linear is:  1.0 \n",
      "\n",
      "Testing accuracy for rbf is:  0.7545180722891566\n",
      "Training accuracy for rbf is:  0.9801409352978859 \n",
      "\n",
      "Testing accuracy for poly is:  0.28012048192771083\n",
      "Training accuracy for poly is:  0.2453555413196669 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy for linear is: \", test_acc_linear)\n",
    "print(\"Training accuracy for linear is: \", train_acc_linear, \"\\n\")\n",
    "\n",
    "print(\"Testing accuracy for rbf is: \", test_acc_rbf)\n",
    "print(\"Training accuracy for rbf is: \", train_acc_rbf, \"\\n\")\n",
    "\n",
    "print(\"Testing accuracy for poly is: \", test_acc_poly)\n",
    "print(\"Training accuracy for poly is: \", train_acc_poly, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation in c value for Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7409638554216867 is the testing accuracy for our SVM with linear kernel and c =  0.0001\n",
      "0.9724535554131967 is the training accuracy for our SVM with linear kernel and c =  0.0001 \n",
      "\n",
      "0.7560240963855421 is the testing accuracy for our SVM with linear kernel and c =  0.001\n",
      "0.9795003203074952 is the training accuracy for our SVM with linear kernel and c =  0.001 \n",
      "\n",
      "0.7575301204819277 is the testing accuracy for our SVM with linear kernel and c =  0.01\n",
      "0.9801409352978859 is the training accuracy for our SVM with linear kernel and c =  0.01 \n",
      "\n",
      "0.7635542168674698 is the testing accuracy for our SVM with linear kernel and c =  0.1\n",
      "0.988468930172966 is the training accuracy for our SVM with linear kernel and c =  0.1 \n",
      "\n",
      "0.7771084337349398 is the testing accuracy for our SVM with linear kernel and c =  1\n",
      "1.0 is the training accuracy for our SVM with linear kernel and c =  1 \n",
      "\n",
      "0.7740963855421686 is the testing accuracy for our SVM with linear kernel and c =  10\n",
      "1.0 is the training accuracy for our SVM with linear kernel and c =  10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_vals = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "train_acc_carray = []\n",
    "test_acc_carray = []\n",
    "for c in c_vals:\n",
    "    #testing\n",
    "    prob = []\n",
    "    svm_linear(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "    svm_linear(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "    svm_linear(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "    svm_linear(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "    svm_linear(c, train_x, train_y_5_arr, test_x, test_y_5_arr)\n",
    "    \n",
    "    \n",
    "    test_yhat_linear = []\n",
    "    # test_yhat_linear_pac = []\n",
    "    for i in range (0, len(test_x), 1):\n",
    "        values = []\n",
    "        probability_and_classification = []\n",
    "        m1 = prob[0][i][1]\n",
    "        m2 = prob[1][i][1]\n",
    "        m3 = prob[2][i][1]\n",
    "        m4 = prob[3][i][1]\n",
    "        m5 = prob[4][i][1]\n",
    "        values.append(m1)\n",
    "        values.append(m2)\n",
    "        values.append(m3)\n",
    "        values.append(m4)\n",
    "        values.append(m5)\n",
    "        #max_prob = max(m1, m2, m3, m4, m5)\n",
    "\n",
    "    #     probability_and_classification.append(max(values))\n",
    "    #     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "    #     test_yhat_linear_pac.append(probability_and_classification)\n",
    "\n",
    "        test_yhat_linear.append((values.index(max(values))) + 1)\n",
    "    # print(test_yhat_linear) # Correct\n",
    "    \n",
    "    #Calculate testing accuracy\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range (0, 664):\n",
    "        if (test_yhat_linear[i] == test_y[i]):\n",
    "            correct+= 1\n",
    "    #         print(test_yhat_linear[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    #         print(\"INCORRECT\", test_yhat_linear[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "    test_acc_linear = correct/len(test_x)\n",
    "    print(test_acc_linear, \"is the testing accuracy for our SVM with linear kernel and c = \" , c)\n",
    "    test_acc_carray.append(test_acc_linear)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #training accuracy\n",
    "\n",
    "    prob = []\n",
    "    svm_linear(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "    svm_linear(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "    svm_linear(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "    svm_linear(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "    svm_linear(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "    train_yhat_linear = []\n",
    "    for i in range (0, len(train_x), 1):\n",
    "        values = []\n",
    "        probability_and_classification = []\n",
    "        m1 = prob[0][i][1]\n",
    "        m2 = prob[1][i][1]\n",
    "        m3 = prob[2][i][1]\n",
    "        m4 = prob[3][i][1]\n",
    "        m5 = prob[4][i][1]\n",
    "        values.append(m1)\n",
    "        values.append(m2)\n",
    "        values.append(m3)\n",
    "        values.append(m4)\n",
    "        values.append(m5)\n",
    "\n",
    "        train_yhat_linear.append((values.index(max(values))) + 1)\n",
    "    # print(train_yhat_linear) # Correct\n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range (0, len(train_x)):\n",
    "        if (train_yhat_linear[i] == train_y[i]):\n",
    "            correct+= 1\n",
    "    #         print(train_yhat_linear[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    #         print(\"INCORRECT\", train_yhat_linear[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "    train_acc_linear = correct/len(train_x)\n",
    "    train_acc_carray.append(train_acc_linear)\n",
    "    print(train_acc_linear, \"is the training accuracy for our SVM with linear kernel and c = \" , c , \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a208cf320>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcFNW5//HPwyKDiqwGDdtgXCKyCeN2UYOiiCaRuBAxmKuiolGiMcZcIiYact1yk5+KW4IG1IgDKOIlkegVcVyiIhpRNomggAMoyiqbMPD8/jg1Q0/TPd2z9PTM9Pf9evVruk9VnXpOT3c9VaeqT5m7IyIiUpFG2Q5ARETqPiULERFJSclCRERSUrIQEZGUlCxERCQlJQsREUlJySKHmNlmMzuklte5wMz61+Y66wMzczM7tJp1VPjemlmRmV1enXVkgpndZGaPZDuO6jCz/Oh/2CTbsdQWJYtqMLMTzewNM9toZuvM7J9mdoyZnWBmW8ysRYJl3jOzkTEftn/FTW9nZjvMbFlNx+vu+7v7xzVdr5ndamZPJFnnUe5eVNPrrKz4L7cF95nZh2bWIdvxVUXse1vR/6Cucffb3T0jSSz6v15rZvOj72CxmT1lZj0ysb5comRRRWZ2APB34D6gDdAB+C3wtbu/CRQD58Ut0x3oBhTGFO8XlZf6EfBJBkNv8FLt7ZmZAX8G+gPfcfeVNVl/rjOzxllc/b3AdcC1hO/l4cCzwHezGFPD4O56VOEBFAAbKph+EzArruz3wDPR83zAgZuB/4mZ5x1gNLAsSb2lyzWJKSsCLo+eHwq8AmwEvgQmx8znwKHR80eBB4DngK+A2cC3YuYdCCyO6nkwqvPyJDHdCjyRZNoy4LSY+aYAj0frXAAUxMz7TWAq8AUhYV4bM+1Y4E1gA7AauB/YJ65t1wAfAZ9U8L41Ax4D/gW0jZtnOLAIWA+8AHSpqP6o7KqobH30flol6js0QZynAPNiXs8E3o55/Trwg9j3FhgE7AB2ApuB92M+F78D/hm93/8HtEvyf1oEfC/mdZPo89Mnev0U8Fn0eXgVOCpm3keBh4AZwBbgRuBzyn9GzwPmxn9eYv4vFwMronWOjlmuefT/Wh/F+EugOEkbDgN2Acem+R0eCrwTV3Y9MD16/l3gPWAT8Clwa7LvITGf80TfCeB44A3C5/d9oH/MtEuAj6P/0SfAsOpsmzL1yHoA9fUBHACsjT7IZwKt46Z3ir68naPXjQhHG6Vf9NIPW370QWwMHEnYQJ9G1ZNFISHZNALygBNj5otPFusIG+EmwERgUjStXfQFOTeadl3UlppIFtuBs6L23gG8FfP+vAv8BtgHOCT6Ap0RTe8bfeGaRO/BIuBncW17kbA32byC9+1pQmJsFTf9B8CS6H/QhJDE36io/qjs70AroDMhyQ2qRH2JkkUesC36HzQhbKBXAS0IG85tREkuwXv7RFxdRcBSwt518+j1nUn+T78BJsa8/i7wYczr4VEMzYB7iDb8MZ+ljUA/9nzuFgJnxswzDbghPtaY/8vDUYy9gK+BI6PpdxJ2VFoDHYEPSJ4srgKWV+I7vC9hA31YTNkcYGj0vD/QI2pTT0ICjP/+pkwWhF6HtYTPfSPg9Oj1gcB+hO/aEdG8BxOTiOvSQ91QVeTum4AT2fNB/8LMpptZ+2j6p4QP+UXRIgMIX6Ln4qoqZk+CuJiw110dO4EuwDfdfbu7v17BvM+4+9vuXkJIFr2j8rOABe7+TDRtLGGjVRNed/cZ7r4L+Cth4wBwDHCgu49x9x0ezq08TNj7w93fdfe33L3E3ZcRupG+E1f3He6+zt23VbD+gcAUd98QV35ltPyiqM23A73NrEuK+u909w3uvgJ4mT3vYTr17cXdtxOOLk8mHL1+QDia6EdIlh+5+9qK6ogzwd3/HcU8JSa+eE8CZ5vZvtHrH0VlpXGNd/ev3P1rwoawl5m1jFn+f939n+6+O2rDY0SffTNrA5wRW18Cv3X3be7+PmHPu/Rz8UPgdndf7+7FhM9iMm0JR51pcfetwP8CF0ZxHgZ8G5geTS9y93lRmz4g7IjFf+bScREwI/rc73b3Fwn/47Oi6buB7mbW3N1Xu/uCKqwj45QsqiHaEFzi7h2B7oRulHtiZnkM+M/o+Y+BJ919Z4KqHiccil4IVPck5S8BA96OrpYZXsG8sQlgK7B/9PybhKMdADzs8hRXM65k68yLzgF0Ab5pZhtKH4SuvPYAZna4mf3dzD4zs02EjW+7uLo/JbXvAbckeF+6APfGrHsd4X2MPfmdqP5k72E69SXzCmGv9uToeRFhI/Wd6HVlJIuvHHdfQjha+36UMM4m2ribWWMzu9PMlkbv/bJosdj3P/69eSKqa3/CBv81d69oQ57WZzHBemKtJeyZV8aTRMmCkCCfjZIIZnacmb1sZl+Y2UbCkUv8Zy4dXYAhcZ/tE4GD3X0LcEFU92oze87Mvl2FdWSckkUNcfcPCYfjsSernwE6mNkphC6dZEcNUwmH/R+7+/IUq9oS/d03puygmDg+c/cr3P2bhL3bB6twieZqwiE/UHZCuGPy2WvEp4RzAa1iHi3cvXTv6yHgQ0KXwQGERGJxdXga63kD+D5hQ/6juPVfGbf+5u7+RiXrr0x9ycQni1dInSwqE1syhYQN52BgYZRAIGxEBxOOflsSumCg/Ptfbv0eLhp4EziHsKP01yrGVO6zSOjeTeYloKOZFVSi/v8D2plZb0LbY49+niQcZXRy95bAn9j7M1dqC0m+k4TPwl/jPgv7ufudAO7+grufTkh0HxKOqOscJYsqMrNvm9kNZtYxet2J8GF7q3SeaK/haWACoS/1nUR1RfOdCqS8nNDdvwBWAhdFe3zDgW/FxDWkNCbCSUEnnPSrjOeAHmb2g2iv/xrKf/gTaWRmeTGPZpVc59vAJjP7LzNrHrWtu5kdE01vQejb3Rztef2kkvWXcfdXCMl7nJmdHxX/CfiVmR0FYGYtzWxIVddRzfreAI4gnE96O+qW6AIcRzi5nMjnQL6ZVec7PYnQTfcTym80WxDOI6wlbBBvT7O+xwlHuj0I5yyqYgrhfWwdXeI8MtmM7v4R4WKMQjPrb2b7RJ/FoWY2KskyJYTv6P8Qzke9GDO5BbDO3beb2bGEpJnMXGComTWNktX5MdNKj7LOiD7XeVF8Hc2svZmdbWb7Ed7jzVT++1orlCyq7ivCl3e2mW0hJIn5wA1x8z1G+KJXeC7C3d9x96VprvsKwhUna4GjCBuXUsdEMW0m7BVd5+6fpFlvaSxfAkMIV2+tJVzu+w7hw5zMhYSTr6WPdNtSus5dhD3+3oQrQr4EHiHsyQL8gvBl/Yqw5zW5MvUnWN+LhMP/R83s++4+DbgLmBR1tcwnXLhQ1fqrXF+08/AvwnmjHVHxm4QdjjVJFnsq+rvW4n67U4mYV0fr+Q/Kv7+PA8sJOykLidkhSmEa4bM/LWpTVYwhdIF+Qrgy7Gkq/hxeS7hS7gHClUdLCUc3f6tgmScJR01PRcmj1NXAGDP7inABwJQK6vg1YadtPeES+tjzPZ8SjsxuIlwE8Snh+9soetxAuIhhHeHo8eoK1pM1FrqjRZKL9laLCZf0vZzteKT+MLOlhO64mTVU308IVytV5USzVIOOLCSh6JC5VdSdVHp+IN09ShHM7DxCN+isatRxsJn1M7NGZnYEYS+8ql1aUg36JaokcwLhUHofQtfDD1JckipSxsyKCN2XP3b33dWoah/CZdJdCd1KkwjnJaSWqRtKRERSUjeUiIik1GC6odq1a+f5+flVXn7Lli3st99+NRdQPZBrbc619oLanCuq0+Z33333S3c/MNV8DSZZ5Ofn8847CX/GkJaioiL69+9fcwHVA7nW5lxrL6jNuaI6bTazVD8EBtQNJSIiaVCyEBGRlJQsREQkJSULERFJSclCRERSyliyMLPxZrbGzOYnmW5mNtbMlpjZB2bWJ2baxWb2UfS4OFMxZtXEiZCfD40ahb8TJ2Y7IhGpb6LtyHdOPTXj25FMXjr7KGH0x2SjrZ5JuGfuYYTRWx8CjovuqnUL4S5hDrxrZtPdfX0GY61dEyfCiBGwdWt4vXx5eA0wbFj24hKR+iNmO2KQ8e1IxpKFu79qZvkVzDIYeDy6C9tb0aB1BxNu+vKiu68DMLMXCTekL8xUrLVu9Og9iaLU1q1wzTWweHGthZG/bBnMqvIYb/VOrrUX1OYGbezYxNuR0aPrV7JIQwfK3yKxOCpLVr4XMxsBjABo3749RUVFVQ5m8+bN1Vo+HU03bKDdP//J4cuXJ7zdlm/cCP/93xmNIVYXaub2avVFrrUX1OYGzT3xdmTFCl7JwLYsm8kiYTsrKN+70H0cMA6goKDAq/OrzYz96rO4GKZNg2eegVdfhd27oUkTKCnZa1br0gWWLav5GJLItV+65lp7QW1u0PLzQ9dTHOvcOSPtz+bVUMWUv59uR8LdopKV1x9LlsDvfw/HHw+dOsG118IXX4TDw7lz4dFHYd99yy+z775w221ZCVdE6qHbbqvV7Ug2jyymAyPNbBLhBPdGd19tZi8At5tZ62i+gcCvshVkWtxh/nyYOjUcQcybF8oLCuCOO+Ccc+CII/bM36tX+Dt6NKxYAZ07h3+wTm6LSLpKtxejR+MrVmAZ3o5kLFmYWSHhZHU7MysmXOHUFMDd/wTMAM4ClgBbgUujaevM7HfAnKiqMaUnu+uU3bthzpyQHJ55JhxNmMFJJ8E994QE0blz8uWHDVNyEJHqibYjr9RC11smr4a6MMV0B65JMm08MD4TcVVLSQm8/vqeBLFyZTj/MGAA3HgjDB4M7dtnO0oRkRqnX3DHSvRDua+/hhkz4PLL4eCD4ZRT4OGH4Zhj4K9/hTVr4Pnnw/XNShQi0kA1mPtZVNc3Zs6Eu+8u/0O5iy8OSWL7dmjRAr7/fTj3XBg0CHLs5ioiktuULCKHPPLI3j9w2bUL8vLguedCV1OzZtkJTkQky5QsIs3WrEk8YetWOOus2g1GRKSO0TmLyNff+EbiCRVd0SQikiOULCIrzz5770L9UE5EBFCyKLsC6pCHHw6v27QJv5fo0gXGjdNvIUREyPVzFhMnwvDhsGPHngGpNm8Ol8QqSYiIlMntI4vrroMdO8qX7dgRykVEpExuJ4u1aytXLiKSo3I7WYiISFpyO1m0bVu5chGRHJXbyeLee6Fx4/JljRuHchERKZPbyQLCoIEVvRYRkRxPFqNHw86d5ct27gzlIiJSJreTxYoVlSsXEclRuZ0sko37pPGgRETKye1kUcs3PBcRqa9yO1kMGxbGf+rSBdd4UCIiSeV2soCQGJYt45VZs2DZMiUKEZEElCxERCQlJQsREUlJyUJERFJSshARkZSULEREJCUlCxERSUnJQkREUlKyEBGRlJQsREQkpYwmCzMbZGaLzWyJmY1KML2Lmb1kZh+YWZGZdYyZtsvM5kaP6ZmMU0REKtYkUxWbWWPgAeB0oBiYY2bT3X1hzGx/AB5398fM7FTgDuDH0bRt7t47U/GJiEj6MnlkcSywxN0/dvcdwCRgcNw83YCXoucvJ5guIiJ1gLl7Zio2Ox8Y5O6XR69/DBzn7iNj5nkSmO3u95rZucBUoJ27rzWzEmAuUALc6e7PJljHCGAEQPv27ftOmjSpyvFu3ryZ/fffv8rL10e51uZcay+ozbmiOm0+5ZRT3nX3glTzZawbCrAEZfGZ6RfA/WZ2CfAqsJKQHAA6u/sqMzsEmGVm89x9abnK3McB4wAKCgq8f//+VQ62qKiI6ixfH+Vam3OtvaA254raaHMmk0Ux0CnmdUdgVewM7r4KOBfAzPYHznP3jTHTcPePzawIOBoolyxERKR2ZPKcxRzgMDPramb7AEOBclc1mVk7MyuN4VfA+Ki8tZk1K50H6AfEnhgXEZFalLFk4e4lwEjgBWARMMXdF5jZGDM7O5qtP7DYzP4NtAdK72d6JPCOmb1POPF9Z9xVVCIiUosy2Q2Fu88AZsSV/Sbm+dPA0wmWewPokcnYREQkffoFt4iIpKRkISIiKSlZiIhISkoWIiKSkpKFiIikpGQhIiIpKVmIiEhKShYiIpKSkoWIiKSkZCEiIikpWYiISEpKFiIikpKShYiIpKRkISIiKSlZiIhISkoWIiKSkpKFiIikpGQhIiIpKVmIiEhKShYiIpKSkoWIiKSkZCEiIikpWYiISEpKFiIikpKShYiIpKRkISIiKSlZiIhISkoWIiKSkpKFiIiklNFkYWaDzGyxmS0xs1EJpncxs5fM7AMzKzKzjjHTLjazj6LHxZmMU0REKpaxZGFmjYEHgDOBbsCFZtYtbrY/AI+7e09gDHBHtGwb4BbgOOBY4BYza52pWEVEpGKZPLI4Flji7h+7+w5gEjA4bp5uwEvR85djpp8BvOju69x9PfAiMCiDsYqISAUymSw6AJ/GvC6OymK9D5wXPT8HaGFmbdNcVkREakmTDNZtCco87vUvgPvN7BLgVWAlUJLmspjZCGAEQPv27SkqKqpysJs3b67W8vVRrrU519oLanOuqI02ZzJZFAOdYl53BFbFzuDuq4BzAcxsf+A8d99oZsVA/7hli+JX4O7jgHEABQUF3r9///hZ0lZUVER1lq+Pcq3NudZeUJtzRW20OWU3lJmNrOLJ5TnAYWbW1cz2AYYC0+PqbmdmpTH8ChgfPX8BGGhmraN1D4zKREQkC9I5Z3EQMMfMpkSXwibqItqLu5cAIwkb+UXAFHdfYGZjzOzsaLb+wGIz+zfQHrgtWnYd8DtCwpkDjInKREQkC1J2Q7n7zWb2a8Le/aWEcwxTgL+4+9IUy84AZsSV/Sbm+dPA00mWHc+eIw0REcmitK6GcncHPoseJUBr4Gkz+30GYxMRkToi5ZGFmV0LXAx8CTwC3OjuO6NzDR8Bv8xsiCJS03bu3ElxcTHbt2/Pdig1rmXLlixatCjbYdSqdNqcl5dHx44dadq0aZXWkc7VUO2Ac919eWyhu+82s+9Vaa0iklXFxcW0aNGC/Px80jwNWW989dVXtGjRItth1KpUbXZ31q5dS3FxMV27dq3SOtLphpoBlJ1cNrMWZnZcFEBupW+RBmL79u20bdu2wSUKSczMaNu2bbWOJNNJFg8Bm2Neb4nKRKQeU6LILdX9f6eTLCw6wQ2E7icy+2M+EWng1q5dS+/evenduzcHHXQQHTp0KHu9Y8eOtOq49NJLWbx4cYXzPPDAA0ycOLEmQgbg888/p0mTJvzlL3+psTrri3SSxcdmdq2ZNY0e1wEfZzowEalDJk6E/Hxo1Cj8reYGuG3btsydO5e5c+dy1VVXcf3115e93meffYDQz7579+6kdUyYMIEjjjiiwvVcc801DBs2rFqxxpo8eTInnHAChYWFNVZnIiUlJRmtvyrSSRZXAf9BGLepmDBs+IhMBiUidcjEiTBiBCxfDu7h74gR1U4YiSxZsoTu3btz1VVX0adPH1avXs2IESMoKCjgqKOOYsyYMWXznnjiicydO5eSkhJatWrFqFGj6NWrFwMGDGDNmjUA3Hzzzdxzzz1l848aNYpjjz2WI444gjfeeAOALVu2cN5559GrVy8uvPBCCgoKmDt3bsL4CgsLueeee/j444/57LPPysqfe+45+vTpQ69evRg4cCAQTjpffPHF9OjRg549e/Lss8+WxVpq0qRJXH755QBcdNFF3HDDDZxyyincdNNNvPXWW5xwwgkcffTR9OvXj48++ggIieT666+ne/fu9OzZkwcffJCZM2cyZMiQsnr/8Y9/8MMf/rDa/49Y6fwobw1hqA4RaYh+9jNIsnEE4K234Ouvy5dt3QqXXQYPP5x4md69IdpIV9bChQuZMGECf/rTnwC48847adOmDSUlJZxyyimcf/75dOtW/tY4Gzdu5Dvf+Q533nknI0eOZPz48Ywatdf91nB33n77baZPn86YMWN4/vnnue+++zjooIOYOnUq77//Pn369EkY17Jly1i/fj19+/bl/PPPZ8qUKVx77bV89tln/OQnP+G1116jS5curFsXrge69dZbOfDAA5k3bx7uzoYNG1K2fenSpbz00ks0atSIjRs38vrrr9O4cWOef/55br75ZiZPnsxDDz3EqlWreP/992ncuDHr1q2jcePGjBo1irVr19K2bVsmTJjApZdeWtm3vkLpjA2VZ2bXmNmDZja+9FGjUYhI3RWfKFKVV9O3vvUtjjnmmLLXhYWF9OnThz59+rBo0SIWLly41zLNmzfnzDPPBKB3794sW7YsYd3nnnsuAH379i2b5/XXX2fo0LA/3KtXL4466qiEyxYWFnLBBRcAMHTo0LKuqDfffJNTTjmFLl26ANCmTRsAZs6cyTXXXAOEk8utW6ceYm/IkCE0ahQ2yxs2bODcc8+le/fu/OIXv2DBggVl9V511VU0bty4bH2NGjXiRz/6EU8++STr1q3j3XffLTvCqSnpnKj+K/Ah4YZEY4BhhLGeRKQhSHUEkJ8fup7idekCGRgWe7/99it7/tFHH3Hvvffy9ttv06pVKy666KKEl3+WnucAaNy4cdI+/2bNmu01T8z1OxUqLCxk7dq1PPbYYwCsWrWKTz75BHdPeKVRovJGjRqVW198W2LbPnr0aM444wyuvvpqlixZwqBBg5LWCzB8+HDOOy/cHuiCCy4oSyY1JZ1zFoe6+6+BLe7+GPBdoEeNRiEidddtt8G++5Yv23ffUJ5hmzZtokWLFhxwwAGsXr2aF16o+cGnTzzxRKZMmQLAvHnzEh65LFy4kF27drFy5UqWLVvGsmXLuPHGG5k0aRL9+vVj1qxZLI8Samk31MCBA7n//vuBsIFfv349jRo1onXr1nz00Ufs3r2badOmJY1r48aNdOgQ7vn26KOPlpUPHDiQhx56iF27dpVbX6dOnWjXrh133nknl1xySfXelATSSRY7o78bzKw70BLIr/FIRKRuGjYMxo0LRxJm4e+4caE8w/r06UO3bt3o3r07V1xxBf369avxdfz0pz9l5cqV9OzZkz/+8Y90796dli1blpvnySef5JxzzilXdt555/Hkk0/Svn17HnroIQYPHkyvXr3Krr665ZZb+Pzzz+nevTu9e/fmtddeA+Cuu+5i0KBBDBgwgI4dOyaN67/+67+48cYb92rzlVdeyUEHHUTPnj3p1atXWaID+NGPfkTXrl05/PDDq/WeJOTuFT6AywkDB55MuGR2DXBlquVq+9G3b1+vjpdffrlay9dHudbmXGuve/I2L1y4sHYDqUWbNm2q1Pw7d+70bdu2ubv7v//9b8/Pz/edO3dmIrSMKW3zlVde6Y8++mjS+RL934F3PI1tbIXnLKLBAje5+3rCbU8Pqfl0JSKSPZs3b2bAgAGUlJTg7vz5z3+mSZP697vj3r1707p1a8aOHZuR+it8RzwMFjgSmFLRfCIi9VWrVq149913sx1GtSX7bUhNSeecxYtm9gsz62RmbUofGY1KRETqlHSOtYZHf6+JKXPUJSUikjPS+QV31QY/FxGRBiOdO+X9Z6Jyd3+85sMREZG6KJ1zFsfEPE4CbgXOzmBMItLA1cQQ5QDjx48vN6BfvB07dtCmTRt+/etf10TYOS1lsnD3n8Y8rgCOBvZJtZyINBw1PEJ5WkOUpyNVsnj++efp1q0bkydPrl7AKdTFIcVrWjpHFvG2AofVdCAiUjfV4gjlADz22GMce+yx9O7dm6uvvprdu3dTUlLCj3/8Y3r06EH37t0ZO3YskydPZu7cuVxwwQVJj0gKCwv5+c9/Tvv27ZkzZ05Z+ezZsznhhBPo1asXxx13HFu3bk049DdAx44dy0aMfeuttzjttNOAMPz5lVdeyemnn86ll17K0qVLOemkkzj66KPp27cvs2fPLlvf7bffTo8ePejVqxejR49m8eLFHHvssWXTFy1aVO51XZTOOYu/Ea5+gpBcuqHfXYg0GHVphPL58+czbdo03njjDZo0acKIESOYNGkS3/rWt/jyyy+ZN28eEEZkbdWqFffddx/3338/vXv33quuLVu28MorrzBhwgQ+++wzCgsLOeaYY9i+fTtDhw5l6tSp9OnTh40bN9KsWTMefPDBvYb+TuW9997j1VdfJS8vj61bt/Liiy+Sl5fHhx9+yMUXX8zs2bP529/+xj/+8Q/efvttmjdvzrp162jTpg15eXnMnz+f7t27Z2RI8ZqWzqWzf4h5XgIsd/fiDMUjInVMbY5QPnPmTObMmUNBQQEA27Zto1OnTpxxxhksXryY6667jrPOOiut4benT5/O6aefTl5eHkOGDKGgoIA//OEPLFq0iM6dO5fdt6J0HKiZM2fys5/9rNzQ36kMHjyYvLw8AL7++mtGjhzJ+++/T5MmTVi6dGlZvcOHD6d58+bl6r3sssuYMGECd911F0899RTvvfdeZd6qWpdOslgBrHb37QBm1tzM8t19WUYjE5FaUZdGKHd3hg8fzu9+97u9pn3wwQf84x//YOzYsUydOpVx48ZVWFdhYSGzZ88mPz8fgDVr1vDqq69ywAEHpD2kOECTJk3Kbu9a0ZDif/zjH+nUqRNPPPEEO3fuZP/996+w3iFDhnD77bfTr18/TjjhhHJ30KuL0jln8RQQeyPcXVGZiOSA2hyh/LTTTmPKlCl8+eWXQLhqasWKFXzxxRe4O0OGDOG3v/0t//rXvwBo0aIFX3311V71rF+/ntmzZ1NcXFw2pPjYsWMpLCzkqKOOYvny5WV1bNq0iV27diUd+js/P79sOJCpU6cmjX3jxo0cfPDBmBmPPfZY2X0rBg4cyF/+8he2bdtWrt59992XU089lZEjR9b5LihIL1k0cfeyM0fRc10NJZIjanOE8h49enDLLbdw2mmn0bNnTwYOHMjnn3/Op59+ysknn0zv3r254ooruP322wG49NJLufzyy/c6wT116lROP/10mjZtWlb2gx/8gGnTptGoUSMKCwv5yU9+UnbP7K+//jrp0N+33norV199NSeddFKFV2qNHDmSRx55hOOPP57ly5eX3Wjpe9/7HoMGDaKgoIDevXtz9913ly2sNnTWAAAUdklEQVQzbNgwmjZtyoABA2r0fcyIVMPSAi8CZ8e8Hgy8lM6QtrX50BDllZdrbc619rpriPK67o477vBbb7212vWk2+aMDVEeuQqYaGb3R6+LgYS/6hYRkfR8//vf59NPP2XWrFnZDiUt6YwNtRQ43sz2B8zd9+4gTMLMBgH3Ao2BR9z9zrjpnYHHgFbRPKPcfYaZ5RPu8704mvUtd78q3fWKiNR1f/vb37IdQqWkPGdhZrebWSt33+zuX5lZazP77zSWaww8AJxJ+G3GhWbWLW62m4Ep7n40MBR4MGbaUnfvHT2UKEREsiidE9xnuvuG0hce7pp3VhrLHQsscfePPZwUn0Q43xHLgQOi5y2BVWnUKyI1wN1TzyQNRnX/3+mcs2hsZs3c/WsIv7MAmqWxXAfg05jXxcBxcfPcCvyfmf0U2A84LWZaVzN7D9gE3Ozur8WvwMxGACMA2rdvT1E1LvrevHlztZavj3KtzbnWXkje5v3335/i4mJatmyZ8DcA9dmuXbsSXk7bkKVqs7uzceNGtmzZUuXvQDrJ4gngJTObEL2+lHCeIZVEn8D41HYh8Ki7/9HMTgD+ambdgdVAZ3dfa2Z9gWfN7Ch331SuMvdxwDiAgoIC79+/fxphJVZUVER1lq+Pcq3NudZeSN7mnTt3UlxczMqVK2s/qAzbvn172a+qc0U6bc7Ly6NXr17lLieujHROcP/ezD4g7PUb8DzQJY26i4FOMa87snc302XAoGg9b5pZHtDO3dcAX0fl75rZUuBw4J001isiKTRt2pSuXRvmfc2Kioo4+uijsx1GraqNNqc76uxnhF9xnwcMIFyplMoc4DAz62pm+xBOYE+Pm2dFVB9mdiSQB3xhZgdGJ8gxs0MIo9x+nGasIiJSw5IeWZjZ4YQN/IXAWmAy4dLZU9Kp2N1LzGwk8ALhstjx7r7AzMYQfgQyHbgBeNjMrid0UV3i7m5mJwNjzKyEMLzIVe6eeghIERHJiIq6oT4EXgO+7+5LAKKNetrcfQYwI67sNzHPFwL9Eiw3FUg+CIuIiNSqirqhziN0P71sZg+b2QASn7QWEZEGLmmycPdp7n4B8G2gCLgeaG9mD5lZ6sHkRUSkwUjnHtxb3H2iu3+PcEXTXGBUxiMTEZE6o1L34Hb3de7+Z3c/NVMBiYhI3VOpZCEiIrlJyUJERFJSshARkZSULEREJCUlCxERSUnJQkREUlKyEBGRlJQsREQkJSULERFJSclCRERSUrIQEZGUlCxERCQlJQsREUlJyUJERFJSshARkZSULEREJCUlCxERSUnJQkREUlKyEBGRlJQsREQkJSULERFJSclCRERSUrIQEZGUlCxERCQlJQsREUkpo8nCzAaZ2WIzW2JmoxJM72xmL5vZe2b2gZmdFTPtV9Fyi83sjEzGKSIiFWuSqYrNrDHwAHA6UAzMMbPp7r4wZrabgSnu/pCZdQNmAPnR86HAUcA3gZlmdri778pUvCIiklwmjyyOBZa4+8fuvgOYBAyOm8eBA6LnLYFV0fPBwCR3/9rdPwGWRPWJiEgWZOzIAugAfBrzuhg4Lm6eW4H/M7OfAvsBp8Us+1bcsh3iV2BmI4ARAO3bt6eoqKjKwW7evLlay9dHudbmXGsvqM25ojbanMlkYQnKPO71hcCj7v5HMzsB+KuZdU9zWdx9HDAOoKCgwPv371/lYIuKiqjO8vVRrrU519oLanOuqI02ZzJZFAOdYl53ZE83U6nLgEEA7v6mmeUB7dJcVkREakkmz1nMAQ4zs65mtg/hhPX0uHlWAAMAzOxIIA/4IppvqJk1M7OuwGHA2xmMVUREKpCxIwt3LzGzkcALQGNgvLsvMLMxwDvuPh24AXjYzK4ndDNd4u4OLDCzKcBCoAS4RldCiYhkTya7oXD3GYTLYWPLfhPzfCHQL8mytwG3ZTI+ERFJj37BLSIiKSlZiIhISkoWIiKSkpKFiIikpGQhIiIpKVmIiEhKShYiIpKSkoWIiKSkZJElEydCfj40ahT+TpyY7YhERJLL6C+4JbGJE2HECNi6Nbxevjy8Bhg2LHtxiYgko2SRBaNH70kUpbZuhWuvhR07wtFG7KNx473LUk1LZ5kVK5rz0UfVX1ejRmCJBpUXkQZDyaKWrVgRjiQSWbcOhg+vzWji70VVdWZVT1o1nQSTTfviiyN55JHaWVdttquiaStX5vHJJ9WLQzsCddfEiWHnc8WK79C5M9x2W+Z6J5QsasHWrTBtGkyYALNmJZ+vQwf45z9h9+69H7t2Va48nWnz5y/k29/uVmP1VXZaTdRXUpL+Mlu2tGD58urH53vdhqsuO75GaqlPCXLNmm/z+OMNL/HHl/3973DzzbBtG4BlvDtbySJD3OGtt0KCmDwZNm0KJ7JvuQVatty7K2rffeGuu6BLl9qLsX37NfTv3632VphlRUVv079//2rX4548KWUzcSYqX7BgEUcccWSdT/qJymN3BCpT39atrVi4sGqx168dgb1t3Rq2LUoW9cCqVfD44/Doo7B4cUgC558Pl14KJ58c9ggADjyw9PCRjB8+Ss0yC3t6jRtnO5LUioo+p3//I7MdRq0qKnqryjsF7nt2BupC4qxoWrLtxYoVVX/vKqJkUQO2b4fp00OCeOGF8I886ST45S9hyBBo0WLvZYYNU3IQqWvM9px/a1LHt4433ZT4/GfnzplZXx1/O+oud3j33ZAgnnwS1q+Hjh3hV7+CSy6BQw/NdoQi0pDddlv5S/Ah9GTclqFbxilZVNLnn4crECZMgPnzIS8PzjkndDOdemr96JoQkfqvtGcidGc7nTubrobKth07YMaMkCBmzAgn3o47Dv70J7jgAmjVKtsRikguKu3OLip6pUYu3qiIkkWMPdcsh36/K6+ENWvgiSfgyy/hoIPg5z8P3UxH5tY5QxHJcUoWkZkzv8Hdd5cfguOmm0K3Umk308CBdf+kl4hIJmjTF3nkkUP2GoID4OCD4amnaj8eEZG6pFG2A6gr1qxplrB85cpaDkREpA7K+WRROlR4sl9uZuqaZRGR+iSnu6EmTgwD9+3YAbD3aGmZvGZZRKQ+yekji+uuK00Ue+vSBcaN06+sRUQgx48s1q5NPm3ZsloLQ0SkzsvpIwsREUlPTieLtm0rVy4ikqsymizMbJCZLTazJWY2KsH0u81sbvT4t5ltiJm2K2ba9EzEd++90LRp+bKmTUO5iIjskbFzFmbWGHgAOB0oBuaY2XR3X1g6j7tfHzP/T4GjY6rY5u69MxUfhJPXW7aEYT3A6dIlswNxiYjUV5k8sjgWWOLuH7v7DmASMLiC+S8ECjMYT0JDhoS/11yzhGXLlChERBLJ5NVQHYBPY14XA8clmtHMugBdgVkxxXlm9g5QAtzp7s8mWG4EMAKgffv2FBUVVTrITZuaACeyY8eOKi1fn23evDmn2pxr7QW1OVfURpszmSz2/pUbJLvD7VDgaXffFVPW2d1XmdkhwCwzm+fuS8tV5j4OGAdQUFDgVRmid9268LdZs30yPsRvXVNUVJRTbc619oLanCtqo82Z7IYqBjrFvO4IrEoy71DiuqDcfVX092OgiPLnM2pMfb9Bu4hIbchkspgDHGZmXc1sH0JC2OuqJjM7AmgNvBlT1trMmkXP2wH9gIXxy9YkS3QcJCIiQAaThbuXACOBF4BFwBR3X2BmY8zs7JhZLwQmuZfbxz8SeMfM3gdeJpyzyEiyKB1+/L77DiU/P4wXJSIi5WV0uA93nwHMiCv7TdzrWxMs9wbQI5OxQUgMP/956Stj+fJwA3TQVVEiIrFy+hfco0fDtm3ly7ZuDeUiIrJHTieLFSsqVy4ikqtyOlkku7GRbngkIlJeTieL224LNziKpRseiYjsLaeTxbBh4QZHXbqAmeuGRyIiSeR0soCQGJYtg1mzXtHYUCIiSeR8shARkdSULEREJCUlCxERSUnJQkREUlKyEBGRlMwbyBjdZvYFsLwaVbQDvqyhcOqLXGtzrrUX1OZcUZ02d3H3A1PN1GCSRXWZ2TvuXpDtOGpTrrU519oLanOuqI02qxtKRERSUrIQEZGUlCz2GJftALIg19qca+0FtTlXZLzNOmchIiIp6chCRERSUrIQEZGUcj5ZmNkgM1tsZkvMbFS248k0M+tkZi+b2SIzW2Bm12U7ptpiZo3N7D0z+3u2Y6kNZtbKzJ42sw+j//cJ2Y4p08zs+uhzPd/MCs0sL9sx1TQzG29ma8xsfkxZGzN70cw+iv62run15nSyMLPGwAPAmUA34EIz65bdqDKuBLjB3Y8EjgeuyYE2l7oOWJTtIGrRvcDz7v5toBcNvO1m1gG4Fihw9+5AY2BodqPKiEeBQXFlo4CX3P0w4KXodY3K6WQBHAsscfeP3X0HMAkYnOWYMsrdV7v7v6LnXxE2IB2yG1XmmVlH4LvAI9mOpTaY2QHAycBfANx9h7tvyG5UtaIJ0NzMmgD7AquyHE+Nc/dXgXVxxYOBx6LnjwE/qOn15nqy6AB8GvO6mBzYcJYys3zgaGB2diOpFfcAvwR2ZzuQWnII8AUwIep6e8TM9st2UJnk7iuBPwArgNXARnf/v+xGVWvau/tqCDuEwDdqegW5niwsQVlOXEtsZvsDU4GfufumbMeTSWb2PWCNu7+b7VhqUROgD/CQux8NbCEDXRN1SdRPPxjoCnwT2M/MLspuVA1HrieLYqBTzOuONMDD1nhm1pSQKCa6+zPZjqcW9APONrNlhK7GU83sieyGlHHFQLG7lx41Pk1IHg3ZacAn7v6Fu+8EngH+I8sx1ZbPzexggOjvmppeQa4niznAYWbW1cz2IZwMm57lmDLKzIzQj73I3f9ftuOpDe7+K3fv6O75hP/xLHdv0Huc7v4Z8KmZHREVDQAWZjGk2rACON7M9o0+5wNo4Cf1Y0wHLo6eXwz8b02voElNV1ifuHuJmY0EXiBcOTHe3RdkOaxM6wf8GJhnZnOjspvcfUYWY5LM+CkwMdoR+hi4NMvxZJS7zzazp4F/Ea76e48GOPSHmRUC/YF2ZlYM3ALcCUwxs8sISXNIja9Xw32IiEgqud4NJSIiaVCyEBGRlJQsREQkJSULERFJSclCRERSUrJoYMzsIDObZGZLzWyhmc0ws8NroN7NNRFfBfUfbWaPRM/NzMZGIwF/YGYJf0xmZn3NbF4039jo2vqkI3BWVK+ZPW9mG9IdkdbMmpnZ5Kiu2dHQKYnmSziqcfTbntlRjJOjy1sxs5PN7F9mVmJm56cZS8L3IW6ebLR9r9FRU9T7bTN708y+NrNfpLnMyCgON7N2MeUJ22tmB5rZ8+nULeUpWTQg0UZiGlDk7t9y927ATUD77EaWlpuA+6LnZwKHRY8RwENJlnkoml46b+lInMlG4Kyo3v8h/P4kXZcB6939UOBu4K74GaziUY3vAu6OYlwf1QfhGvlLgCcrEUuy9yFWrbY98miSWJJZRxg19g+VWOafhF9uL48rT9hed/8CWG1m/SqxDkHJoqE5Bdjp7n8qLXD3ue7+WuxMZnaXmV0d8/pWM7vBzPY3s5eiPdt5ZrbXCLxm1j92D9TM7jezS6Lnfc3sFTN718xesD3DD1wbHeV8YGaTEtTZAujp7u9HRYOBxz14C2hVWlfMMgcDB7j7mx5+LPQ4e0baTDYCZ9J63f0l4Kuk7+zeYtfxNDAgwR59wlGNo/lOjZYrF6O7L3P3D0hzwMMU70N8vLXZ9mSjoybl7mvcfQ6wsxLLvOfuy5LEmOwz9CwwLN11SKBk0bB0B9IZLG8ScEHM6x8CTwHbgXPcvQ8h8fwx0UYgEQvjTd0HnO/ufYHxwG3R5FHA0e7eE7gqweIFQGxXRTqjAXeIyhPNk2wEzpocZbisLncvATYCbZPNE7e+tsCGaLmaiCPZ+5BOLFVdZ6q2Z1tF7X0HOKnWI6rncnq4j1zl7u+Z2TfM7JvAgYQuhRXRBv92MzuZsGfbgdCF9Vka1R5BSFYvRvmlMWGYaIAPCMNOPEvYq4t3MGE47VLpjAZclRGDa3KU4erEWNtxVGa+mlxnNlUU4xrCqLRSCUoWDcsCIK2TooTug/OBgwhHGhAOzQ8E+rr7TgujtMbflrKE8kekpdMNWODuiW7d+V3CjXjOBn5tZkfF7FUDbItbTzqjARdH5Ynm+dzMDnb31VZ+BM6aHGW4tK5iCzfaacneXS7J1vcloVukSfQ+VDeOZO9DOrFUdZ2p2p5tFbU3j/CZk0pQN1TDMgtoZmZXlBaY2TFm9p0E804ijMB6Pnv6zlsS7vuw08xOAbokWG450C26IqYlYWRPgMXAgRbd59nMmprZUWbWCOjk7i8Tbj7UCtg/rs5FwKExr6cD/xld0XI84SY2q2MXiF5/ZWbHR11l/8mekTaTjcCZst54ZnaHmZ2TYFLsOs4njGQbv3edcFTjaL6X2ZPY0xol1Mw+jC9L8T7Ex1ubba+o3pEWBvBMW3QurTLdZhW193DKd3tKOtxdjwb0IBxeTwGWEo40ngMOSzLvPODlmNftgDcJfbqPEDbi+dG0zTHz/Z6QHP5OuGfAJVF5b+BV4P1o3VcATYHXo3XNB0ZVEEuL6LkRriJaGpUXxMw3N+Z56bmOpcD97BkYsy3hKqiPor9t0qj3NUJX2DbCXukZUfnfgRMSxJtHOM+zBHgbOCTm/Z8RM99ZwL+jdY6OKT8kWm5JVE+zqPyYaP1bgLWEo7XS/83iJO9dsvfhKuCqLLa9kNAVuTOq97Ko/H7gwgT1HhTNtwnYED0/gLBTuxxonmCZa6P5SghHDo+k0d5fAD/N9ne1vj006qzUCWZ2PfCVu9epe2Sb2QvufkYdiON7hI3y2FpcZ0baHl1Nd66HK8TSmb87MNzdf15D638VGOzu62uivlyhZCF1gpnlAUPc/a/ZjkUaLjM7EOjn7okutJAKKFmIiEhKOsEtIiIpKVmIiEhKShYiIpKSkoWIiKSkZCEiIin9f03zbCtk6tIWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c_vals, train_acc_carray, 'ro-') \n",
    "plt.plot(c_vals, test_acc_carray,'bo-') \n",
    "plt.grid()\n",
    "plt.title(\"SVM using Linear Kernel with varying C values\")\n",
    "plt.xlabel(\"C values (0.0001, 0.001, 0.01, 0.1, 1, 10)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# Use the following function to have a legend\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'], loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
