{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import os\n",
    "import re\n",
    "os.chdir(\"./Desktop/ArticleClassifier\")\n",
    "\n",
    "# Changing the kernels being used and the c values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through 70% of the text files from each category (folder)\n",
    "# 70% Training, 30% Testing for each category\n",
    "#Creates training_titles and testing_tiles\n",
    "training_titles_files = []\n",
    "testing_titles_files = [] \n",
    "\n",
    "business_files = os.listdir(\"./business\")\n",
    "train_business = business_files[0:358]\n",
    "test_business = business_files[358:] # length = 152, TOTAL = 510 \n",
    "training_titles_files.append(train_business)\n",
    "testing_titles_files.append(test_business)\n",
    "\n",
    "entertainment_files = os.listdir(\"./entertainment\")\n",
    "train_entertainment = entertainment_files[0:270]\n",
    "test_entertainment = entertainment_files[270:] # 116, TOTAL = 386\n",
    "training_titles_files.append(train_entertainment)\n",
    "testing_titles_files.append(test_entertainment)\n",
    "\n",
    "politics_files = os.listdir(\"./politics\")\n",
    "train_politics = politics_files[0:293]\n",
    "test_politics = politics_files[293:] # 124, TOTAL = 417\n",
    "training_titles_files.append(train_politics)\n",
    "testing_titles_files.append(test_politics)\n",
    "\n",
    "sport_files = os.listdir(\"./sport\")\n",
    "train_sport = sport_files[0:359]\n",
    "test_sport = sport_files[359:] # 152, TOTAL = 511\n",
    "training_titles_files.append(train_sport)\n",
    "testing_titles_files.append(test_sport)\n",
    "\n",
    "tech_files = os.listdir(\"./tech\")\n",
    "train_tech = tech_files[0:281]\n",
    "test_tech = tech_files[281:] # 120, TOTAL = 401\n",
    "training_titles_files.append(train_tech)\n",
    "testing_titles_files.append(test_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text_file = open(\"trainingTextFile.txt\", \"w\")\n",
    "\n",
    "classes = 1\n",
    "for i in training_titles_files:\n",
    "\tfolder_name = \"\"\n",
    "\tif (classes == 1): \n",
    "\t\tfolder_name = \"business\"\n",
    "\telif (classes == 2):\n",
    "\t\tfolder_name = \"entertainment\"\n",
    "\telif (classes == 3):\n",
    "\t\tfolder_name = \"politics\"\n",
    "\telif (classes == 4):\n",
    "\t\tfolder_name = \"sport\"\n",
    "\telif (classes == 5):\n",
    "\t\tfolder_name = \"tech\"\n",
    "\tfor file_name in i:\n",
    "\t\tfile = \"./\" + folder_name + \"/\" + file_name\n",
    "\t\t#print(file)\n",
    "\t\topened = open(file, \"r\")\n",
    "\t\ttraining_text_file.write(opened.readline())\n",
    "\t\topened.close()\n",
    "\tclasses = classes + 1\n",
    "\n",
    "training_text_file.close()\n",
    "\n",
    "masterTestDataFile = open(\"testTextFile.txt\", \"w\")\n",
    "\n",
    "classes = 1\n",
    "for i in testing_titles_files:\n",
    "\tfolder_name = \"\"\n",
    "\tif (classes == 1): \n",
    "\t\tfolder_name = \"business\"\n",
    "\telif (classes == 2):\n",
    "\t\tfolder_name = \"entertainment\"\n",
    "\telif (classes == 3):\n",
    "\t\tfolder_name = \"politics\"\n",
    "\telif (classes == 4):\n",
    "\t\tfolder_name = \"sport\"\n",
    "\telif (classes == 5):\n",
    "\t\tfolder_name = \"tech\"\n",
    "\tfor file_name in i:\n",
    "\t\tfile = \"./\" + folder_name + \"/\" + file_name\n",
    "\t\t#print (file)\n",
    "\t\topened = open(file, \"r\")\n",
    "\t\tlineRead = opened.readline()\n",
    "\t\t#try: \n",
    "\t\tmasterTestDataFile.write(lineRead)\n",
    "\t\t#except UnicodeDecodeError:\n",
    "\t\topened.close()\n",
    "\tclasses = classes + 1\n",
    "\n",
    "masterTestDataFile.close()\n",
    "\n",
    "#currency stemming nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "testing = []\n",
    "\n",
    "# Puts words in dictionary, key = word, value = index\n",
    "trfile = open(\"trainingTextFile.txt\", \"r\")\n",
    "\n",
    "for line in trfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tnew_line = line.split()\n",
    "\tfor i in new_line:\n",
    "\t\ttraining.append(i)\n",
    "\n",
    "trfile.close()\n",
    "\n",
    "words = {}\n",
    "count = 0\n",
    "for i in training:\n",
    "\tif i not in words:\n",
    "\t\twords[i] = count\n",
    "\t\tcount = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Training Data Matrix\n",
    "d = len(words) # Number of features (unique words) we have in the dictionary\n",
    "# print(d)\n",
    "train_x = []\n",
    "\n",
    "trfile = open(\"trainingTextFile.txt\", \"r\")\n",
    "\n",
    "for line in trfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tword = line.split()\n",
    "\tarr = [0] * d\n",
    "\tfor i in word:\n",
    "\t\tindex = words[i]\n",
    "\t\tarr[index] = arr[index] + 1\n",
    "\ttrain_x.append(arr)\n",
    "trfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Training Vector\n",
    "train_y = np.zeros((1561, 1))\n",
    "for i in range(0, 1561):\n",
    "    if i >=0 and i < 358:\n",
    "        train_y[i] = 1\n",
    "    elif i >= 358 and i < 628:\n",
    "        train_y[i] = 2\n",
    "    elif i >= 628 and i < 921:\n",
    "        train_y[i] = 3\n",
    "    elif i >= 921 and i < 1280:\n",
    "        train_y[i] = 4\n",
    "    elif i >= 1280 and i < 1561:\n",
    "        train_y[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Testing Data Matrix\n",
    "test_x = []\n",
    "\n",
    "testfile = open(\"testTextFile.txt\", \"r\")\n",
    "\n",
    "for line in testfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tword = line.split()\n",
    "\tarr = [0] * d\n",
    "\tfor i in word:\n",
    "\t\tif i in words:\n",
    "\t\t\tindex = words[i]\n",
    "\t\t\tarr[index] = arr[index] + 1\n",
    "\ttest_x.append(arr)\n",
    "\n",
    "testfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Test Vector\n",
    "test_y = np.zeros((664, 1))\n",
    "for i in range(0, 664):\n",
    "    if i >= 0 and i < 152:\n",
    "        test_y[i] = 1\n",
    "    elif i >= 152 and i < 268:\n",
    "        test_y[i] = 2\n",
    "    elif i >= 268 and i < 392:\n",
    "        test_y[i] = 3\n",
    "    elif i >= 392 and i < 544:\n",
    "        test_y[i] = 4\n",
    "    elif i >= 544 and i < 664:\n",
    "        test_y[i] = 5\n",
    "    else:\n",
    "        test_y[i] = 1\n",
    "\n",
    "# countzero = 0\n",
    "# countone = 0\n",
    "# counttwo = 0\n",
    "# countthree = 0\n",
    "# countfour = 0\n",
    "# for i in test_y:\n",
    "# \tif i == 0:\n",
    "# \t\tcountzero+=1\n",
    "# \tif i == 1:\n",
    "# \t\tcountone += 1\n",
    "# \tif i == 2:\n",
    "# \t\tcounttwo+=1 \n",
    "# \tif i == 3:\n",
    "# \t\tcountthree+=1\n",
    "# \tif i == 4:\n",
    "# \t\tcountfour +=1\n",
    "\n",
    "#print(countzero)\n",
    "#print(countone)\n",
    "#print(counttwo)\n",
    "#print(countthree)\n",
    "#print(countfour)\n",
    "\n",
    "\n",
    "# y = 0 --> Business\n",
    "# y = 1 --> Entertainment\n",
    "# y = 2 --> Politics\n",
    "# y = 3 --> Sport\n",
    "# y = 4 --> Tech\n",
    "\n",
    "# print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training for each classification\n",
    "train_y_1 = train_y.copy()\n",
    "train_y_2 = train_y.copy()\n",
    "train_y_3 = train_y.copy()\n",
    "train_y_4 = train_y.copy()\n",
    "train_y_5 = train_y.copy()\n",
    "\n",
    "# Changing the values that aren't the classified values to 0\n",
    "train_y_1[train_y_1 != 1] = 0\n",
    "train_y_2[train_y_2 != 2] = 0\n",
    "train_y_3[train_y_3 != 3] = 0\n",
    "train_y_4[train_y_4 != 4] = 0\n",
    "train_y_5[train_y_5 != 5] = 0\n",
    "\n",
    "# Changes the correct classification values to 1 so it's easier\n",
    "train_y_2[train_y_2 == 2] = 1\n",
    "train_y_3[train_y_3 == 3] = 1\n",
    "train_y_4[train_y_4 == 4] = 1\n",
    "train_y_5[train_y_5 == 5] = 1\n",
    "\n",
    "train_y_1_arr = []\n",
    "train_y_2_arr = []\n",
    "train_y_3_arr = []\n",
    "train_y_4_arr = []\n",
    "train_y_5_arr = []\n",
    "\n",
    "for i in range(0, 1561):\n",
    "    train_y_1_arr.insert(i, int(train_y_1[i][0]))\n",
    "    train_y_2_arr.insert(i, int(train_y_2[i][0]))\n",
    "    train_y_3_arr.insert(i, int(train_y_3[i][0]))\n",
    "    train_y_4_arr.insert(i, int(train_y_4[i][0]))\n",
    "    train_y_5_arr.insert(i, int(train_y_5[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for each classification\n",
    "test_y_1 = test_y.copy()\n",
    "test_y_2 = test_y.copy()\n",
    "test_y_3 = test_y.copy()\n",
    "test_y_4 = test_y.copy()\n",
    "test_y_5 = test_y.copy()\n",
    "\n",
    "# Changing the values that aren't the classified values to 0\n",
    "test_y_1[test_y_1 != 1] = 0\n",
    "test_y_2[test_y_2 != 2] = 0\n",
    "test_y_3[test_y_3 != 3] = 0\n",
    "test_y_4[test_y_4 != 4] = 0\n",
    "test_y_5[test_y_5 != 5] = 0\n",
    "\n",
    "# Changes the correct classification values to 1 so it's easier\n",
    "test_y_2[test_y_2 == 2] = 1\n",
    "test_y_3[test_y_3 == 3] = 1\n",
    "test_y_4[test_y_4 == 4] = 1\n",
    "test_y_5[test_y_5 == 5] = 1\n",
    "\n",
    "test_y_1_arr = []\n",
    "test_y_2_arr = []\n",
    "test_y_3_arr = []\n",
    "test_y_4_arr = []\n",
    "test_y_5_arr = []\n",
    "\n",
    "for i in range(0, 664):\n",
    "    test_y_1_arr.insert(i, int(test_y_1[i][0]))\n",
    "    test_y_2_arr.insert(i, int(test_y_2[i][0]))\n",
    "    test_y_3_arr.insert(i, int(test_y_3[i][0]))\n",
    "    test_y_4_arr.insert(i, int(test_y_4[i][0]))\n",
    "    test_y_5_arr.insert(i, int(test_y_5[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "def logreg_model(c , X_train, Y_train, X_test, Y_test):\n",
    "    logreg = linear_model.LogisticRegression(C=c,penalty='l1', warm_start=True, solver='saga')\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    Yhat_train = logreg.predict(X_train)\n",
    "    Yhat_test = logreg.predict(X_test)\n",
    "    prob.append(logreg.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 1, 4, 5, 4, 1, 4, 1, 1, 5, 4, 1, 1, 1, 1, 1, 1, 3, 4, 3, 1, 3, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 5, 3, 4, 1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 5, 1, 1, 4, 1, 3, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 5, 3, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 4, 3, 4, 4, 1, 4, 4, 1, 5, 1, 4, 1, 1, 1, 4, 1, 4, 4, 4, 3, 1, 1, 1, 1, 1, 4, 1, 4, 4, 3, 3, 1, 1, 1, 1, 1, 1, 3, 4, 1, 1, 4, 1, 1, 5, 4, 2, 5, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 1, 3, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 4, 1, 3, 1, 2, 2, 2, 4, 2, 2, 3, 5, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 4, 4, 2, 1, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 4, 2, 4, 4, 4, 2, 3, 3, 4, 3, 3, 3, 2, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 2, 1, 3, 3, 3, 3, 2, 3, 4, 3, 3, 3, 3, 4, 3, 3, 3, 4, 2, 3, 4, 4, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 5, 3, 3, 4, 5, 4, 4, 3, 3, 3, 3, 3, 4, 1, 3, 4, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 1, 4, 4, 3, 5, 3, 3, 4, 2, 4, 3, 3, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 2, 3, 3, 3, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 1, 1, 4, 4, 4, 1, 4, 4, 3, 4, 1, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 3, 5, 4, 4, 5, 4, 5, 5, 5, 4, 5, 5, 5, 1, 5, 2, 4, 5, 4, 4, 5, 4, 1, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 5, 2, 2, 3, 5, 5, 5, 2, 1, 5, 5, 5, 5, 3, 4, 5, 4, 5, 1, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 2, 1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 4, 1, 4, 5, 4, 5, 5, 5, 5, 2, 5, 2, 1, 1, 2, 5, 4, 4, 5, 5, 4, 5, 1, 5, 5, 4]\n",
      "0.6837349397590361 is the testing accuracy for our logistic regression with L1 regularization\n"
     ]
    }
   ],
   "source": [
    "#Testing Accuracy\n",
    "c = 1\n",
    "logreg_model(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "logreg_model(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "logreg_model(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "logreg_model(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "logreg_model(c, train_x, train_y_5_arr, test_x, test_y_5_arr)\n",
    "\n",
    "test_yhat_L1 = []\n",
    "# test_yhat_L1_pac = []\n",
    "for i in range (0, len(test_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    #max_prob = max(m1, m2, m3, m4, m5)\n",
    "    \n",
    "#     probability_and_classification.append(max(values))\n",
    "#     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "#     test_yhat_L1_pac.append(probability_and_classification)\n",
    "    \n",
    "    test_yhat_L1.append((values.index(max(values))) + 1)\n",
    "print(test_yhat_L1) # Correct\n",
    "\n",
    "#Calculate testing accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(test_x)):\n",
    "    if (test_yhat_L1[i] == test_y[i]):\n",
    "        correct+= 1\n",
    "#         print(test_yhat_L1[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", test_yhat_L1[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "test_acc_L1 = correct/len(test_x)\n",
    "print(test_acc_L1, \"is the testing accuracy for our logistic regression with L1 regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 4, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 5, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 1, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 4, 2, 3, 2, 4, 2, 2, 5, 5, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 1, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 5, 2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 4, 2, 2, 2, 3, 2, 2, 2, 3, 4, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 1, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 2, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 2, 4, 1, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 1, 5, 4, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 2, 5, 5, 1, 1, 5, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 4, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5]\n",
      "0.9051889814221653 is the training accuracy for our logistic regression with L1 regularization\n"
     ]
    }
   ],
   "source": [
    "#training accuracy\n",
    "c = 1\n",
    "prob = []\n",
    "logreg_model(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "logreg_model(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "logreg_model(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "logreg_model(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "logreg_model(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "train_yhat_L1 = []\n",
    "for i in range (0, len(train_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    \n",
    "    train_yhat_L1.append((values.index(max(values))) + 1)\n",
    "print(train_yhat_L1) # Correct\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(train_x)):\n",
    "    if (train_yhat_L1[i] == train_y[i]):\n",
    "        correct+= 1\n",
    "#         print(train_yhat_L1[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", train_yhat_L1[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "train_acc_L1 = correct/len(train_x)\n",
    "print(train_acc_L1, \"is the training accuracy for our logistic regression with L1 regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg2_model(c , X_train, Y_train, X_test, Y_test):\n",
    "    logreg2 = linear_model.LogisticRegression(C=c, warm_start=True)\n",
    "    logreg2.fit(X_train, Y_train) \n",
    "    Yhat_train = logreg2.predict(X_train)\n",
    "    Yhat_test = logreg2.predict(X_test)\n",
    "    prob.append(logreg2.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 1, 1, 5, 3, 1, 4, 1, 1, 5, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 5, 1, 4, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 3, 1, 4, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 3, 4, 4, 1, 1, 1, 1, 5, 1, 4, 1, 1, 1, 1, 1, 3, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 5, 1, 1, 1, 1, 1, 1, 3, 4, 1, 1, 4, 1, 1, 5, 4, 2, 4, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 1, 4, 4, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 4, 1, 3, 1, 2, 2, 2, 4, 2, 2, 3, 5, 2, 2, 2, 2, 2, 2, 2, 4, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 4, 2, 5, 2, 3, 2, 4, 2, 2, 1, 2, 2, 4, 3, 2, 2, 2, 2, 1, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 3, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 3, 3, 5, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 3, 5, 3, 3, 3, 3, 3, 1, 1, 3, 4, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 5, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 4, 1, 3, 4, 3, 4, 3, 3, 3, 4, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 1, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 2, 4, 4, 4, 4, 3, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 3, 5, 4, 4, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 2, 4, 5, 5, 1, 5, 5, 1, 3, 5, 5, 1, 5, 5, 5, 4, 4, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 1, 2, 2, 3, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 4, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 5, 4, 5, 5, 5, 5, 2, 5, 2, 1, 5, 2, 5, 1, 1, 5, 5, 1, 5, 1, 5, 5, 4]\n",
      "0.7484939759036144 is the testing accuracy for our logistic regression with L2 regularization\n"
     ]
    }
   ],
   "source": [
    "#Testing Accuracy\n",
    "prob = []\n",
    "c = 1\n",
    "logreg2_model(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "logreg2_model(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "logreg2_model(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "logreg2_model(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "logreg2_model(c, train_x, train_y_5_arr, test_x, test_y_5_arr)\n",
    "\n",
    "test_yhat_L2 = []\n",
    "# test_yhat_L2_pac = []\n",
    "for i in range (0, len(test_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    #max_prob = max(m1, m2, m3, m4, m5)\n",
    "    \n",
    "#     probability_and_classification.append(max(values))\n",
    "#     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "#     test_yhat_L2_pac.append(probability_and_classification)\n",
    "    \n",
    "    test_yhat_L2.append((values.index(max(values))) + 1)\n",
    "print(test_yhat_L2) # Correct\n",
    "\n",
    "#Calculate testing accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(test_x)):\n",
    "    if (test_yhat_L2[i] == test_y[i]):\n",
    "        correct+= 1\n",
    "#         print(test_yhat_L2[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", test_yhat_L2[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "test_acc_L2 = correct/len(test_x)\n",
    "print(test_acc_L2, \"is the testing accuracy for our logistic regression with L2 regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "0.9987187700192185 is the training accuracy for our logistic regression with L2 regularization\n"
     ]
    }
   ],
   "source": [
    "#training accuracy\n",
    "c = 1\n",
    "prob = []\n",
    "logreg2_model(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "logreg2_model(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "logreg2_model(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "logreg2_model(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "logreg2_model(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "train_yhat_L2 = []\n",
    "for i in range (0, len(train_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    \n",
    "    train_yhat_L2.append((values.index(max(values))) + 1)\n",
    "print(train_yhat_L2) # Correct\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(train_x)):\n",
    "    if (train_yhat_L2[i] == train_y[i]):\n",
    "        correct+= 1\n",
    "#         print(train_yhat_L2[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", train_yhat_L2[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "train_acc_L2 = correct/len(train_x)\n",
    "print(train_acc_L2, \"is the training accuracy for our logistic regression with L2 regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37198795180722893 is the testing accuracy for logistic regression with regularization L2 and c = 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43113388853299167 is the training accuracy for logistic regression with regularization L2 and c = 0.0001 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375 is the testing accuracy for logistic regression with regularization L2 and c = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43625880845611786 is the training accuracy for logistic regression with regularization L2 and c = 0.001 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4457831325301205 is the testing accuracy for logistic regression with regularization L2 and c = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5759128763613068 is the training accuracy for logistic regression with regularization L2 and c = 0.01 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.661144578313253 is the testing accuracy for logistic regression with regularization L2 and c = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9007046764894299 is the training accuracy for logistic regression with regularization L2 and c = 0.1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7484939759036144 is the testing accuracy for logistic regression with regularization L2 and c = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987187700192185 is the training accuracy for logistic regression with regularization L2 and c = 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7635542168674698 is the testing accuracy for logistic regression with regularization L2 and c = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jackyteoh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 is the training accuracy for logistic regression with regularization L2 and c = 10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#change logreg2_model to best regulariazation above\n",
    "c_vals = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "train_acc_carray = []\n",
    "test_acc_carray = []\n",
    "for c in c_vals:\n",
    "    #testing\n",
    "    prob = []\n",
    "    logreg2_model(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "    logreg2_model(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "    logreg2_model(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "    logreg2_model(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "    logreg2_model(c, train_x, train_y_5_arr, test_x, test_y_5_arr)\n",
    "    \n",
    "    test_yhat_linear = []\n",
    "    # test_yhat_linear_pac = []\n",
    "    for i in range (0, len(test_x), 1):\n",
    "        values = []\n",
    "        probability_and_classification = []\n",
    "        m1 = prob[0][i][1]\n",
    "        m2 = prob[1][i][1]\n",
    "        m3 = prob[2][i][1]\n",
    "        m4 = prob[3][i][1]\n",
    "        m5 = prob[4][i][1]\n",
    "        values.append(m1)\n",
    "        values.append(m2)\n",
    "        values.append(m3)\n",
    "        values.append(m4)\n",
    "        values.append(m5)\n",
    "        #max_prob = max(m1, m2, m3, m4, m5)\n",
    "\n",
    "    #     probability_and_classification.append(max(values))\n",
    "    #     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "    #     test_yhat_linear_pac.append(probability_and_classification)\n",
    "\n",
    "        test_yhat_linear.append((values.index(max(values))) + 1)\n",
    "    # print(test_yhat_linear) # Correct\n",
    "    \n",
    "    #Calculate testing accuracy\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range (0, 664):\n",
    "        if (test_yhat_linear[i] == test_y[i]):\n",
    "            correct+= 1\n",
    "    #         print(test_yhat_linear[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    #         print(\"INCORRECT\", test_yhat_linear[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "    test_acc_linear = correct/len(test_x)\n",
    "    print(test_acc_linear, \"is the testing accuracy for logistic regression with regularization L2 and c =\" , c)\n",
    "    test_acc_carray.append(test_acc_linear)\n",
    "    \n",
    "    \n",
    "    #training accuracy\n",
    "    prob = []\n",
    "    logreg2_model(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "    logreg2_model(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "    logreg2_model(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "    logreg2_model(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "    logreg2_model(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "    train_yhat_linear = []\n",
    "    for i in range (0, len(train_x), 1):\n",
    "        values = []\n",
    "        probability_and_classification = []\n",
    "        m1 = prob[0][i][1]\n",
    "        m2 = prob[1][i][1]\n",
    "        m3 = prob[2][i][1]\n",
    "        m4 = prob[3][i][1]\n",
    "        m5 = prob[4][i][1]\n",
    "        values.append(m1)\n",
    "        values.append(m2)\n",
    "        values.append(m3)\n",
    "        values.append(m4)\n",
    "        values.append(m5)\n",
    "\n",
    "        train_yhat_linear.append((values.index(max(values))) + 1)\n",
    "    # print(train_yhat_linear) # Correct\n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range (0, len(train_x)):\n",
    "        if (train_yhat_linear[i] == train_y[i]):\n",
    "            correct+= 1\n",
    "    #         print(train_yhat_linear[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    #         print(\"INCORRECT\", train_yhat_linear[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "    train_acc_linear = correct/len(train_x)\n",
    "    train_acc_carray.append(train_acc_linear)\n",
    "    print(train_acc_linear, \"is the training accuracy for logistic regression with regularization L2 and c =\" , c , \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a29935dd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c_vals, train_acc_carray, 'ro-') \n",
    "plt.plot(c_vals, test_acc_carray,'bo-') \n",
    "plt.grid()\n",
    "plt.xlabel('C values (0.0001, 0.001, 0.01, 0.1, 1, 10)')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.title('Logistic Regression with L2 Regularization and varying c values')\n",
    "\n",
    "# Use the following function to have a legend\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'], loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
