{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import os\n",
    "import re\n",
    "os.chdir(\"./Desktop/ArticleClassifier\")\n",
    "\n",
    "# Changing the kernels being used and the c values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through 70% of the text files from each category (folder)\n",
    "# 70% Training, 30% Testing for each category\n",
    "#Creates training_titles and testing_tiles\n",
    "training_titles_files = []\n",
    "testing_titles_files = [] \n",
    "\n",
    "business_files = os.listdir(\"./business\")\n",
    "train_business = business_files[0:358]\n",
    "test_business = business_files[358:] # length = 152, TOTAL = 510 \n",
    "training_titles_files.append(train_business)\n",
    "testing_titles_files.append(test_business)\n",
    "\n",
    "entertainment_files = os.listdir(\"./entertainment\")\n",
    "train_entertainment = entertainment_files[0:270]\n",
    "test_entertainment = entertainment_files[270:] # 116, TOTAL = 386\n",
    "training_titles_files.append(train_entertainment)\n",
    "testing_titles_files.append(test_entertainment)\n",
    "\n",
    "politics_files = os.listdir(\"./politics\")\n",
    "train_politics = politics_files[0:293]\n",
    "test_politics = politics_files[293:] # 124, TOTAL = 417\n",
    "training_titles_files.append(train_politics)\n",
    "testing_titles_files.append(test_politics)\n",
    "\n",
    "sport_files = os.listdir(\"./sport\")\n",
    "train_sport = sport_files[0:359]\n",
    "test_sport = sport_files[359:] # 152, TOTAL = 511\n",
    "training_titles_files.append(train_sport)\n",
    "testing_titles_files.append(test_sport)\n",
    "\n",
    "tech_files = os.listdir(\"./tech\")\n",
    "train_tech = tech_files[0:281]\n",
    "test_tech = tech_files[281:] # 120, TOTAL = 401\n",
    "training_titles_files.append(train_tech)\n",
    "testing_titles_files.append(test_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text_file = open(\"trainingTextFile.txt\", \"w\")\n",
    "\n",
    "classes = 1\n",
    "for i in training_titles_files:\n",
    "\tfolder_name = \"\"\n",
    "\tif (classes == 1): \n",
    "\t\tfolder_name = \"business\"\n",
    "\telif (classes == 2):\n",
    "\t\tfolder_name = \"entertainment\"\n",
    "\telif (classes == 3):\n",
    "\t\tfolder_name = \"politics\"\n",
    "\telif (classes == 4):\n",
    "\t\tfolder_name = \"sport\"\n",
    "\telif (classes == 5):\n",
    "\t\tfolder_name = \"tech\"\n",
    "\tfor file_name in i:\n",
    "\t\tfile = \"./\" + folder_name + \"/\" + file_name\n",
    "\t\t#print(file)\n",
    "\t\topened = open(file, \"r\")\n",
    "\t\ttraining_text_file.write(opened.readline())\n",
    "\t\topened.close()\n",
    "\tclasses = classes + 1\n",
    "\n",
    "training_text_file.close()\n",
    "\n",
    "masterTestDataFile = open(\"testTextFile.txt\", \"w\")\n",
    "\n",
    "classes = 1\n",
    "for i in testing_titles_files:\n",
    "\tfolder_name = \"\"\n",
    "\tif (classes == 1): \n",
    "\t\tfolder_name = \"business\"\n",
    "\telif (classes == 2):\n",
    "\t\tfolder_name = \"entertainment\"\n",
    "\telif (classes == 3):\n",
    "\t\tfolder_name = \"politics\"\n",
    "\telif (classes == 4):\n",
    "\t\tfolder_name = \"sport\"\n",
    "\telif (classes == 5):\n",
    "\t\tfolder_name = \"tech\"\n",
    "\tfor file_name in i:\n",
    "\t\tfile = \"./\" + folder_name + \"/\" + file_name\n",
    "\t\t#print (file)\n",
    "\t\topened = open(file, \"r\")\n",
    "\t\tlineRead = opened.readline()\n",
    "\t\t#try: \n",
    "\t\tmasterTestDataFile.write(lineRead)\n",
    "\t\t#except UnicodeDecodeError:\n",
    "\t\topened.close()\n",
    "\tclasses = classes + 1\n",
    "\n",
    "masterTestDataFile.close()\n",
    "\n",
    "#currency stemming nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "testing = []\n",
    "\n",
    "# Puts words in dictionary, key = word, value = index\n",
    "trfile = open(\"trainingTextFile.txt\", \"r\")\n",
    "\n",
    "for line in trfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tnew_line = line.split()\n",
    "\tfor i in new_line:\n",
    "\t\ttraining.append(i)\n",
    "\n",
    "trfile.close()\n",
    "\n",
    "words = {}\n",
    "count = 0\n",
    "for i in training:\n",
    "\tif i not in words:\n",
    "\t\twords[i] = count\n",
    "\t\tcount = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Training Data Matrix\n",
    "d = len(words) # Number of features (unique words) we have in the dictionary\n",
    "# print(d)\n",
    "train_x = []\n",
    "\n",
    "trfile = open(\"trainingTextFile.txt\", \"r\")\n",
    "\n",
    "for line in trfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tword = line.split()\n",
    "\tarr = [0] * d\n",
    "\tfor i in word:\n",
    "\t\tindex = words[i]\n",
    "\t\tarr[index] = arr[index] + 1\n",
    "\ttrain_x.append(arr)\n",
    "trfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Training Vector\n",
    "train_y = np.zeros((1561, 1))\n",
    "for i in range(0, 1561):\n",
    "    if i >=0 and i < 358:\n",
    "        train_y[i] = 1\n",
    "    elif i >= 358 and i < 628:\n",
    "        train_y[i] = 2\n",
    "    elif i >= 628 and i < 921:\n",
    "        train_y[i] = 3\n",
    "    elif i >= 921 and i < 1280:\n",
    "        train_y[i] = 4\n",
    "    elif i >= 1280 and i < 1561:\n",
    "        train_y[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Testing Data Matrix\n",
    "test_x = []\n",
    "\n",
    "testfile = open(\"testTextFile.txt\", \"r\")\n",
    "\n",
    "for line in testfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tword = line.split()\n",
    "\tarr = [0] * d\n",
    "\tfor i in word:\n",
    "\t\tif i in words:\n",
    "\t\t\tindex = words[i]\n",
    "\t\t\tarr[index] = arr[index] + 1\n",
    "\ttest_x.append(arr)\n",
    "\n",
    "testfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Test Vector\n",
    "test_y = np.zeros((664, 1))\n",
    "for i in range(0, 664):\n",
    "    if i >= 0 and i < 152:\n",
    "        test_y[i] = 1\n",
    "    elif i >= 152 and i < 268:\n",
    "        test_y[i] = 2\n",
    "    elif i >= 268 and i < 392:\n",
    "        test_y[i] = 3\n",
    "    elif i >= 392 and i < 544:\n",
    "        test_y[i] = 4\n",
    "    elif i >= 544 and i < 664:\n",
    "        test_y[i] = 5\n",
    "    else:\n",
    "        test_y[i] = 1\n",
    "\n",
    "# countzero = 0\n",
    "# countone = 0\n",
    "# counttwo = 0\n",
    "# countthree = 0\n",
    "# countfour = 0\n",
    "# for i in test_y:\n",
    "# \tif i == 0:\n",
    "# \t\tcountzero+=1\n",
    "# \tif i == 1:\n",
    "# \t\tcountone += 1\n",
    "# \tif i == 2:\n",
    "# \t\tcounttwo+=1 \n",
    "# \tif i == 3:\n",
    "# \t\tcountthree+=1\n",
    "# \tif i == 4:\n",
    "# \t\tcountfour +=1\n",
    "\n",
    "#print(countzero)\n",
    "#print(countone)\n",
    "#print(counttwo)\n",
    "#print(countthree)\n",
    "#print(countfour)\n",
    "\n",
    "\n",
    "# y = 0 --> Business\n",
    "# y = 1 --> Entertainment\n",
    "# y = 2 --> Politics\n",
    "# y = 3 --> Sport\n",
    "# y = 4 --> Tech\n",
    "\n",
    "# print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training for each classification\n",
    "train_y_1 = train_y.copy()\n",
    "train_y_2 = train_y.copy()\n",
    "train_y_3 = train_y.copy()\n",
    "train_y_4 = train_y.copy()\n",
    "train_y_5 = train_y.copy()\n",
    "\n",
    "# Changing the values that aren't the classified values to 0\n",
    "train_y_1[train_y_1 != 1] = 0\n",
    "train_y_2[train_y_2 != 2] = 0\n",
    "train_y_3[train_y_3 != 3] = 0\n",
    "train_y_4[train_y_4 != 4] = 0\n",
    "train_y_5[train_y_5 != 5] = 0\n",
    "\n",
    "# Changes the correct classification values to 1 so it's easier\n",
    "train_y_2[train_y_2 == 2] = 1\n",
    "train_y_3[train_y_3 == 3] = 1\n",
    "train_y_4[train_y_4 == 4] = 1\n",
    "train_y_5[train_y_5 == 5] = 1\n",
    "\n",
    "train_y_1_arr = []\n",
    "train_y_2_arr = []\n",
    "train_y_3_arr = []\n",
    "train_y_4_arr = []\n",
    "train_y_5_arr = []\n",
    "\n",
    "for i in range(0, 1561):\n",
    "    train_y_1_arr.insert(i, int(train_y_1[i][0]))\n",
    "    train_y_2_arr.insert(i, int(train_y_2[i][0]))\n",
    "    train_y_3_arr.insert(i, int(train_y_3[i][0]))\n",
    "    train_y_4_arr.insert(i, int(train_y_4[i][0]))\n",
    "    train_y_5_arr.insert(i, int(train_y_5[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for each classification\n",
    "test_y_1 = test_y.copy()\n",
    "test_y_2 = test_y.copy()\n",
    "test_y_3 = test_y.copy()\n",
    "test_y_4 = test_y.copy()\n",
    "test_y_5 = test_y.copy()\n",
    "\n",
    "# Changing the values that aren't the classified values to 0\n",
    "test_y_1[test_y_1 != 1] = 0\n",
    "test_y_2[test_y_2 != 2] = 0\n",
    "test_y_3[test_y_3 != 3] = 0\n",
    "test_y_4[test_y_4 != 4] = 0\n",
    "test_y_5[test_y_5 != 5] = 0\n",
    "\n",
    "# Changes the correct classification values to 1 so it's easier\n",
    "test_y_2[test_y_2 == 2] = 1\n",
    "test_y_3[test_y_3 == 3] = 1\n",
    "test_y_4[test_y_4 == 4] = 1\n",
    "test_y_5[test_y_5 == 5] = 1\n",
    "\n",
    "test_y_1_arr = []\n",
    "test_y_2_arr = []\n",
    "test_y_3_arr = []\n",
    "test_y_4_arr = []\n",
    "test_y_5_arr = []\n",
    "\n",
    "for i in range(0, 664):\n",
    "    test_y_1_arr.insert(i, int(test_y_1[i][0]))\n",
    "    test_y_2_arr.insert(i, int(test_y_2[i][0]))\n",
    "    test_y_3_arr.insert(i, int(test_y_3[i][0]))\n",
    "    test_y_4_arr.insert(i, int(test_y_4[i][0]))\n",
    "    test_y_5_arr.insert(i, int(test_y_5[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "def logreg_model(c , X_train, Y_train, X_test, Y_test):\n",
    "    logreg = linear_model.LogisticRegression(C=c,penalty='l1', warm_start=True, solver='saga')\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    Yhat_train = logreg.predict(X_train)\n",
    "    Yhat_test = logreg.predict(X_test)\n",
    "    #prob.append(svc_poly.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy\n",
    "c = 1\n",
    "logreg_model(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "logreg_model(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "logreg_model(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "logreg_model(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "logreg_model(c, train_x, train_y_5_arr, test_x, test_y_5_arr)\n",
    "\n",
    "test_yhat_L1 = []\n",
    "# test_yhat_L1_pac = []\n",
    "for i in range (0, len(test_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    #max_prob = max(m1, m2, m3, m4, m5)\n",
    "    \n",
    "#     probability_and_classification.append(max(values))\n",
    "#     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "#     test_yhat_L1_pac.append(probability_and_classification)\n",
    "    \n",
    "    test_yhat_L1.append((values.index(max(values))) + 1)\n",
    "print(test_yhat_L1) # Correct\n",
    "\n",
    "#Calculate testing accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(test_x)):\n",
    "    if (test_yhat_L1[i] == test_y[i]):\n",
    "        correct+= 1\n",
    "#         print(test_yhat_L1[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", test_yhat_L1[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "test_acc_L1 = correct/len(test_x)\n",
    "print(test_acc_L1, \"is the testing accuracy for our logistic regression with L1 regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training accuracy\n",
    "c = 1\n",
    "prob = []\n",
    "logreg_model(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "logreg_model(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "logreg_model(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "logreg_model(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "logreg_model(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "train_yhat_L1 = []\n",
    "for i in range (0, len(train_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    \n",
    "    train_yhat_L1.append((values.index(max(values))) + 1)\n",
    "print(train_yhat_L1) # Correct\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(train_x)):\n",
    "    if (train_yhat_L1[i] == train_y[i]):\n",
    "        correct+= 1\n",
    "#         print(train_yhat_L1[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", train_yhat_L1[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "train_acc_L1 = correct/len(train_x)\n",
    "print(train_acc_L1, \"is the training accuracy for our logistic regression with L1 regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg2_model(c , X_train, Y_train, X_test, Y_test):\n",
    "    logreg2 = linear_model.LogisticRegression(C=c, warm_start=True)\n",
    "    logreg2.fit(X_train, Y_train) \n",
    "    Yhat_train = logreg2.predict(X_train)\n",
    "    Yhat_test = logreg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy\n",
    "c = 1\n",
    "logreg2_model(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "logreg2_model(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "logreg2_model(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "logreg2_model(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "logreg2_model(c, train_x, train_y_5_arr, test_x, test_y_5_arr)\n",
    "\n",
    "test_yhat_L2 = []\n",
    "# test_yhat_L2_pac = []\n",
    "for i in range (0, len(test_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    #max_prob = max(m1, m2, m3, m4, m5)\n",
    "    \n",
    "#     probability_and_classification.append(max(values))\n",
    "#     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "#     test_yhat_L2_pac.append(probability_and_classification)\n",
    "    \n",
    "    test_yhat_L2.append((values.index(max(values))) + 1)\n",
    "print(test_yhat_L2) # Correct\n",
    "\n",
    "#Calculate testing accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(test_x)):\n",
    "    if (test_yhat_L2[i] == test_y[i]):\n",
    "        correct+= 1\n",
    "#         print(test_yhat_L2[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", test_yhat_L2[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "test_acc_L2 = correct/len(test_x)\n",
    "print(test_acc_L2, \"is the testing accuracy for our logistic regression with L2 regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training accuracy\n",
    "c = 1\n",
    "prob = []\n",
    "logreg2_model(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "logreg2_model(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "logreg2_model(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "logreg2_model(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "logreg2_model(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "train_yhat_L2 = []\n",
    "for i in range (0, len(train_x), 1):\n",
    "    values = []\n",
    "    probability_and_classification = []\n",
    "    m1 = prob[0][i][1]\n",
    "    m2 = prob[1][i][1]\n",
    "    m3 = prob[2][i][1]\n",
    "    m4 = prob[3][i][1]\n",
    "    m5 = prob[4][i][1]\n",
    "    values.append(m1)\n",
    "    values.append(m2)\n",
    "    values.append(m3)\n",
    "    values.append(m4)\n",
    "    values.append(m5)\n",
    "    \n",
    "    train_yhat_L2.append((values.index(max(values))) + 1)\n",
    "print(train_yhat_L2) # Correct\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range (0, len(train_x)):\n",
    "    if (train_yhat_L2[i] == train_y[i]):\n",
    "        correct+= 1\n",
    "#         print(train_yhat_L2[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "    else:\n",
    "        incorrect += 1\n",
    "#         print(\"INCORRECT\", train_yhat_L2[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "train_acc_L2 = correct/len(train_x)\n",
    "print(train_acc_L2, \"is the training accuracy for our logistic regression with L2 regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change svm_linear to best regulariazation above\n",
    "c_vals = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "train_acc_carray = []\n",
    "test_acc_carray = []\n",
    "for c in c_vals:\n",
    "    #testing\n",
    "    prob = []\n",
    "    svm_linear(c, train_x, train_y_1_arr, test_x, test_y_1_arr)\n",
    "    svm_linear(c, train_x, train_y_2_arr, test_x, test_y_2_arr)\n",
    "    svm_linear(c, train_x, train_y_3_arr, test_x, test_y_3_arr)\n",
    "    svm_linear(c, train_x, train_y_4_arr, test_x, test_y_4_arr)\n",
    "    svm_linear(c, train_x, train_y_5_arr, test_x, test_y_5_arr)\n",
    "    \n",
    "    \n",
    "    test_yhat_linear = []\n",
    "    # test_yhat_linear_pac = []\n",
    "    for i in range (0, len(test_x), 1):\n",
    "        values = []\n",
    "        probability_and_classification = []\n",
    "        m1 = prob[0][i][1]\n",
    "        m2 = prob[1][i][1]\n",
    "        m3 = prob[2][i][1]\n",
    "        m4 = prob[3][i][1]\n",
    "        m5 = prob[4][i][1]\n",
    "        values.append(m1)\n",
    "        values.append(m2)\n",
    "        values.append(m3)\n",
    "        values.append(m4)\n",
    "        values.append(m5)\n",
    "        #max_prob = max(m1, m2, m3, m4, m5)\n",
    "\n",
    "    #     probability_and_classification.append(max(values))\n",
    "    #     probability_and_classification.append((values.index(max(values))) + 1)\n",
    "    #     test_yhat_linear_pac.append(probability_and_classification)\n",
    "\n",
    "        test_yhat_linear.append((values.index(max(values))) + 1)\n",
    "    # print(test_yhat_linear) # Correct\n",
    "    \n",
    "    #Calculate testing accuracy\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range (0, 664):\n",
    "        if (test_yhat_linear[i] == test_y[i]):\n",
    "            correct+= 1\n",
    "    #         print(test_yhat_linear[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    #         print(\"INCORRECT\", test_yhat_linear[i], \", actual: \", test_y[i][0], \"=\", (test_y[i][0]))\n",
    "\n",
    "    test_acc_linear = correct/len(test_x)\n",
    "    print(test_acc_linear, \"is the testing accuracy for logistic regression with regularization L and c = \" , c)\n",
    "    test_acc_carray.append(test_acc_linear)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #training accuracy\n",
    "    prob = []\n",
    "    svm_linear(c, train_x, train_y_1_arr, train_x, train_y)\n",
    "    svm_linear(c, train_x, train_y_2_arr, train_x, train_y)\n",
    "    svm_linear(c, train_x, train_y_3_arr, train_x, train_y)\n",
    "    svm_linear(c, train_x, train_y_4_arr, train_x, train_y)\n",
    "    svm_linear(c, train_x, train_y_5_arr, train_x, train_y)\n",
    "\n",
    "    train_yhat_linear = []\n",
    "    for i in range (0, len(train_x), 1):\n",
    "        values = []\n",
    "        probability_and_classification = []\n",
    "        m1 = prob[0][i][1]\n",
    "        m2 = prob[1][i][1]\n",
    "        m3 = prob[2][i][1]\n",
    "        m4 = prob[3][i][1]\n",
    "        m5 = prob[4][i][1]\n",
    "        values.append(m1)\n",
    "        values.append(m2)\n",
    "        values.append(m3)\n",
    "        values.append(m4)\n",
    "        values.append(m5)\n",
    "\n",
    "        train_yhat_linear.append((values.index(max(values))) + 1)\n",
    "    # print(train_yhat_linear) # Correct\n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range (0, len(train_x)):\n",
    "        if (train_yhat_linear[i] == train_y[i]):\n",
    "            correct+= 1\n",
    "    #         print(train_yhat_linear[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    #         print(\"INCORRECT\", train_yhat_linear[i], \", actual: \", train_y[i][0], \"=\", (train_y[i][0]))\n",
    "\n",
    "    train_acc_linear = correct/len(train_x)\n",
    "    train_acc_carray.append(train_acc_linear)\n",
    "    print(train_acc_linear, \"is the training accuracy for logistic regression with regularization L  and c = \" , c , \"\\n\")\n",
    "    \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-949a0e1eb787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_carray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ro-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc_carray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bo-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Use the following function to have a legend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c_vals' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(c_vals, train_acc_carray, 'ro-') \n",
    "plt.plot(c_vals, test_acc_carray,'bo-') \n",
    "plt.grid()\n",
    "\n",
    "# Use the following function to have a legend\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'], loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
