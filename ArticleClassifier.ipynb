{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "os.chdir(\"./Desktop/ArticleClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through 70% of the text files from each category (folder)\n",
    "# 70% Training, 30% Testing for each category\n",
    "#Creates training_titles and testing_tiles\n",
    "training_titles_files = []\n",
    "testing_titles_files = [] \n",
    "\n",
    "business_files = os.listdir(\"./business\")\n",
    "train_business = business_files[0:358]\n",
    "test_business = business_files[358:] # length = 152 TOTAL = 510 \n",
    "training_titles_files.append(train_business)\n",
    "testing_titles_files.append(test_business)\n",
    "\n",
    "entertainment_files = os.listdir(\"./entertainment\")\n",
    "train_entertainment = entertainment_files[0:270]\n",
    "test_entertainment = entertainment_files[270:] # 116 TOTAL = 386\n",
    "training_titles_files.append(train_entertainment)\n",
    "testing_titles_files.append(test_entertainment)\n",
    "\n",
    "politics_files = os.listdir(\"./politics\")\n",
    "train_politics = politics_files[0:293]\n",
    "test_politics = politics_files[293:] # 124 # 417\n",
    "training_titles_files.append(train_politics)\n",
    "testing_titles_files.append(test_politics)\n",
    "\n",
    "sport_files = os.listdir(\"./sport\")\n",
    "train_sport = sport_files[0:359]\n",
    "test_sport = sport_files[359:] # 152 # 511\n",
    "training_titles_files.append(train_sport)\n",
    "testing_titles_files.append(test_sport)\n",
    "\n",
    "tech_files = os.listdir(\"./tech\")\n",
    "train_tech = tech_files[0:281]\n",
    "test_tech = tech_files[281:] # 120 #401\n",
    "training_titles_files.append(train_tech)\n",
    "testing_titles_files.append(test_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text_file = open(\"trainingTextFile.txt\", \"w\")\n",
    "\n",
    "classes = 1\n",
    "for i in training_titles_files:\n",
    "\tfolder_name = \"\"\n",
    "\tif (classes == 1): \n",
    "\t\tfolder_name = \"business\"\n",
    "\telif (classes == 2):\n",
    "\t\tfolder_name = \"entertainment\"\n",
    "\telif (classes == 3):\n",
    "\t\tfolder_name = \"politics\"\n",
    "\telif (classes == 4):\n",
    "\t\tfolder_name = \"sport\"\n",
    "\telif (classes == 5):\n",
    "\t\tfolder_name = \"tech\"\n",
    "\tfor file_name in i:\n",
    "\t\tfile = \"./\" + folder_name + \"/\" + file_name\n",
    "\t\t#print(file)\n",
    "\t\topened = open(file, \"r\")\n",
    "\t\ttraining_text_file.write(opened.readline())\n",
    "\t\topened.close()\n",
    "\tclasses = classes + 1\n",
    "\n",
    "training_text_file.close()\n",
    "\n",
    "masterTestDataFile = open(\"testTextFile.txt\", \"w\")\n",
    "\n",
    "classes = 1\n",
    "for i in testing_titles_files:\n",
    "\tfolder_name = \"\"\n",
    "\tif (classes == 1): \n",
    "\t\tfolder_name = \"business\"\n",
    "\telif (classes == 2):\n",
    "\t\tfolder_name = \"entertainment\"\n",
    "\telif (classes == 3):\n",
    "\t\tfolder_name = \"politics\"\n",
    "\telif (classes == 4):\n",
    "\t\tfolder_name = \"sport\"\n",
    "\telif (classes == 5):\n",
    "\t\tfolder_name = \"tech\"\n",
    "\tfor file_name in i:\n",
    "\t\tfile = \"./\" + folder_name + \"/\" + file_name\n",
    "\t\t#print (file)\n",
    "\t\topened = open(file, \"r\")\n",
    "\t\tlineRead = opened.readline()\n",
    "\t\t#try: \n",
    "\t\tmasterTestDataFile.write(lineRead)\n",
    "\t\t#except UnicodeDecodeError:\n",
    "\t\topened.close()\n",
    "\tclasses = classes + 1\n",
    "\n",
    "masterTestDataFile.close()\n",
    "\n",
    "#currency stemming nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "testing = []\n",
    "\n",
    "# Puts words in dictionary, key = word, value = index\n",
    "trfile = open(\"trainingTextFile.txt\", \"r\")\n",
    "\n",
    "for line in trfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tnew_line = line.split()\n",
    "\tfor i in new_line:\n",
    "\t\ttraining.append(i)\n",
    "\n",
    "trfile.close()\n",
    "\n",
    "words = {}\n",
    "count = 0\n",
    "for i in training:\n",
    "\tif i not in words:\n",
    "\t\twords[i] = count\n",
    "\t\tcount = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Training Data Matrix\n",
    "d = len(words) # Number of features (unique words) we have in the dictionary\n",
    "# print(d)\n",
    "train_x = []\n",
    "\n",
    "trfile = open(\"trainingTextFile.txt\", \"r\")\n",
    "\n",
    "for line in trfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tword = line.split()\n",
    "\tarr = [0] * d\n",
    "\tfor i in word:\n",
    "\t\tindex = words[i]\n",
    "\t\tarr[index] = arr[index] + 1\n",
    "\ttrain_x.append(arr)\n",
    "trfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Training Vector\n",
    "train_y = np.zeros((1561, 5))\n",
    "for i in range(0, 1561):\n",
    "\tif i >= 358 and i < 628:\n",
    "\t\ttrain_y[i][1] = 1\n",
    "\telif i >= 628 and i < 921:\n",
    "\t\ttrain_y[i][2] = 1\n",
    "\telif i >= 921 and i < 1280:\n",
    "\t\ttrain_y[i][3] = 1\n",
    "\telif i >= 1280 and i < 1561:\n",
    "\t\ttrain_y[i][4] = 1\n",
    "\telse:\n",
    "\t\ttrain_y[i][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Testing Data Matrix\n",
    "test_x = []\n",
    "\n",
    "testfile = open(\"testTextFile.txt\", \"r\")\n",
    "\n",
    "for line in testfile:\n",
    "\tline = line.replace(\"'\", \"\")\n",
    "\tword = line.split()\n",
    "\tarr = [0] * d\n",
    "\tfor i in word:\n",
    "\t\tif i in words:\n",
    "\t\t\tindex = words[i]\n",
    "\t\t\tarr[index] = arr[index] + 1\n",
    "\ttest_x.append(arr)\n",
    "\n",
    "testfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Test Vector\n",
    "test_y = np.zeros((664, 5))\n",
    "for i in range(152, 664):\n",
    "\tif i >= 152 and i < 268:\n",
    "\t\ttest_y[i][1] = 1\n",
    "\telif i >= 268 and i < 392:\n",
    "\t\ttest_y[i][2] = 1\n",
    "\telif i >= 392 and i < 544:\n",
    "\t\ttest_y[i][3] = 1\n",
    "\telif i >= 544 and i < 664:\n",
    "\t\ttest_y[i][4] = 1\n",
    "\telse:\n",
    "\t\ttest_y[i][0] = 1\n",
    "\n",
    "# countzero = 0\n",
    "# countone = 0\n",
    "# counttwo = 0\n",
    "# countthree = 0\n",
    "# countfour = 0\n",
    "# for i in test_y:\n",
    "# \tif i == 0:\n",
    "# \t\tcountzero+=1\n",
    "# \tif i == 1:\n",
    "# \t\tcountone += 1\n",
    "# \tif i == 2:\n",
    "# \t\tcounttwo+=1 \n",
    "# \tif i == 3:\n",
    "# \t\tcountthree+=1\n",
    "# \tif i == 4:\n",
    "# \t\tcountfour +=1\n",
    "\n",
    "#print(countzero)\n",
    "#print(countone)\n",
    "#print(counttwo)\n",
    "#print(countthree)\n",
    "#print(countfour)\n",
    "\n",
    "\n",
    "# y = 0 --> Business\n",
    "# y = 1 --> Entertainment\n",
    "# y = 2 --> Politics\n",
    "# y = 3 --> Sport\n",
    "# y = 4 --> Tech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating LossHistory Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got from keras.io\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.train_accuracy = []\n",
    "        self.test_accuracy = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('val_loss'))\n",
    "        self.train_accuracy.append(logs.get('acc'))\n",
    "        self.test_accuracy.append(logs.get('val_acc'))\n",
    "\n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks with varying number of hidden layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3454)              11933570  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               1727500   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 13,914,075\n",
      "Trainable params: 13,914,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1561 samples, validate on 664 samples\n",
      "Epoch 1/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 1.5421 - acc: 0.4600 - val_loss: 0.8632 - val_acc: 0.6777\n",
      "Epoch 2/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.2088 - acc: 0.9353 - val_loss: 1.0143 - val_acc: 0.7455\n",
      "Epoch 3/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0405 - acc: 0.9891 - val_loss: 1.6306 - val_acc: 0.7440\n",
      "Epoch 4/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0491 - acc: 0.9917 - val_loss: 1.7530 - val_acc: 0.7349\n",
      "Epoch 5/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0823 - acc: 0.9917 - val_loss: 2.1984 - val_acc: 0.7304\n",
      "Epoch 6/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0719 - acc: 0.9936 - val_loss: 2.6333 - val_acc: 0.7214\n",
      "Epoch 7/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.1367 - acc: 0.9898 - val_loss: 2.6393 - val_acc: 0.7169\n",
      "Epoch 8/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0859 - acc: 0.9942 - val_loss: 2.8858 - val_acc: 0.7033\n",
      "Epoch 9/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.1517 - acc: 0.9885 - val_loss: 2.8362 - val_acc: 0.6867\n",
      "Epoch 10/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.1714 - acc: 0.9865 - val_loss: 3.5310 - val_acc: 0.6642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12f038ac8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch how many big loops\n",
    "# batch = how many times each loop\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "# First model (smallest hidden layers (2))\n",
    "model_one = Sequential()\n",
    "\n",
    "model_one.add(Dense(units = d, input_shape = train_x[0].shape))\n",
    "\n",
    "model_one.add(Dense(units = 500, activation = 'relu'))\n",
    "model_one.add(Dense(units = 500, activation = 'relu'))\n",
    "\n",
    "model_one.add(Dense(units = 5, activation = 'softmax'))\n",
    "\n",
    "model_one.summary()\n",
    "\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "model_one.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model_one.fit(train_x, train_y, batch_size = 200, epochs = 10, validation_data = (test_x, test_y), callbacks = [history])\n",
    "\n",
    "#epochs=20, batch_size=42, validation_data=(X_ts, Y_ts), callbacks=[history_cb])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 3454)              11933570  \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 500)               1727500   \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 14,415,075\n",
      "Trainable params: 14,415,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1561 samples, validate on 664 samples\n",
      "Epoch 1/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 2.3084 - acc: 0.2652 - val_loss: 1.2961 - val_acc: 0.4187\n",
      "Epoch 2/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 1.0191 - acc: 0.6611 - val_loss: 0.6427 - val_acc: 0.6491\n",
      "Epoch 3/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.3872 - acc: 0.8917 - val_loss: 0.6727 - val_acc: 0.7259\n",
      "Epoch 4/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.1406 - acc: 0.9731 - val_loss: 0.8459 - val_acc: 0.7184\n",
      "Epoch 5/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0771 - acc: 0.9898 - val_loss: 0.9354 - val_acc: 0.7304\n",
      "Epoch 6/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0841 - acc: 0.9904 - val_loss: 1.2378 - val_acc: 0.7319\n",
      "Epoch 7/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0792 - acc: 0.9917 - val_loss: 1.3987 - val_acc: 0.7440\n",
      "Epoch 8/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0975 - acc: 0.9917 - val_loss: 1.7635 - val_acc: 0.7349\n",
      "Epoch 9/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0966 - acc: 0.9827 - val_loss: 1.4695 - val_acc: 0.7154\n",
      "Epoch 10/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0842 - acc: 0.9930 - val_loss: 1.9652 - val_acc: 0.7364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb4ca3bc88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second model (Medium hidden layers (4))\n",
    "model_two = Sequential()\n",
    "\n",
    "model_two.add(Dense(units = d, input_shape = train_x[0].shape))\n",
    "\n",
    "model_two.add(Dense(units = 500, activation = 'relu'))\n",
    "model_two.add(Dense(units = 500, activation = 'relu'))\n",
    "model_two.add(Dense(units = 500, activation = 'relu'))\n",
    "model_two.add(Dense(units = 500, activation = 'relu'))\n",
    "\n",
    "model_two.add(Dense(units = 5, activation = 'softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "model_two.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_two.summary()\n",
    "\n",
    "model_two.fit(train_x, train_y, batch_size = 200, epochs = 10, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 3454)              11933570  \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 500)               1727500   \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 14,916,075\n",
      "Trainable params: 14,916,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1561 samples, validate on 664 samples\n",
      "Epoch 1/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 1.9581 - acc: 0.1992 - val_loss: 1.2011 - val_acc: 0.2515\n",
      "Epoch 2/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 1.4875 - acc: 0.4094 - val_loss: 1.2901 - val_acc: 0.2816\n",
      "Epoch 3/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 1.4173 - acc: 0.5426 - val_loss: 1.2746 - val_acc: 0.4639\n",
      "Epoch 4/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.7293 - acc: 0.7559 - val_loss: 1.1939 - val_acc: 0.5316\n",
      "Epoch 5/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.3897 - acc: 0.8930 - val_loss: 0.8950 - val_acc: 0.6657\n",
      "Epoch 6/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.1987 - acc: 0.9596 - val_loss: 0.8346 - val_acc: 0.7018\n",
      "Epoch 7/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.1097 - acc: 0.9904 - val_loss: 0.9918 - val_acc: 0.7169\n",
      "Epoch 8/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0921 - acc: 0.9923 - val_loss: 1.0324 - val_acc: 0.7199\n",
      "Epoch 9/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0725 - acc: 0.9955 - val_loss: 1.4263 - val_acc: 0.7214\n",
      "Epoch 10/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0725 - acc: 0.9955 - val_loss: 1.7321 - val_acc: 0.7123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc766fb5f8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third model (Large hidden layers (6))\n",
    "model_three = Sequential()\n",
    "\n",
    "model_three.add(Dense(units = d, input_shape = train_x[0].shape))\n",
    "\n",
    "model_three.add(Dense(units = 500, activation = 'relu'))\n",
    "model_three.add(Dense(units = 500, activation = 'relu'))\n",
    "model_three.add(Dense(units = 500, activation = 'relu'))\n",
    "model_three.add(Dense(units = 500, activation = 'relu'))\n",
    "model_three.add(Dense(units = 500, activation = 'relu'))\n",
    "model_three.add(Dense(units = 500, activation = 'relu'))\n",
    "\n",
    "model_three.add(Dense(units = 5, activation = 'softmax'))\n",
    "\n",
    "model_three.summary()\n",
    "\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "model_three.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model_three.fit(train_x, train_y, batch_size = 200, epochs = 10, validation_data = (test_x, test_y))\n",
    "\n",
    "#We think this has lower accuracy bc of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks (Second Model) with varying activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 3454)              11933570  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               1727500   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 14,415,075\n",
      "Trainable params: 14,415,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1561 samples, validate on 664 samples\n",
      "Epoch 1/10\n",
      "1561/1561 [==============================] - 2s 2ms/step - loss: 5.6786 - acc: 0.1941 - val_loss: 4.8363 - val_acc: 0.2289\n",
      "Epoch 2/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 4.5527 - acc: 0.2114 - val_loss: 3.8183 - val_acc: 0.2289\n",
      "Epoch 3/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 4.2457 - acc: 0.2268 - val_loss: 3.8326 - val_acc: 0.2289\n",
      "Epoch 4/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 4.2033 - acc: 0.2140 - val_loss: 3.9011 - val_acc: 0.1747\n",
      "Epoch 5/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 4.1691 - acc: 0.2204 - val_loss: 3.8558 - val_acc: 0.1747\n",
      "Epoch 6/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 4.1733 - acc: 0.1980 - val_loss: 3.8611 - val_acc: 0.2289\n",
      "Epoch 7/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 4.1750 - acc: 0.2082 - val_loss: 3.8515 - val_acc: 0.2289\n",
      "Epoch 8/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 4.1654 - acc: 0.2184 - val_loss: 3.8861 - val_acc: 0.2289\n",
      "Epoch 9/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 4.1671 - acc: 0.2133 - val_loss: 3.9241 - val_acc: 0.2289\n",
      "Epoch 10/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 4.1610 - acc: 0.2293 - val_loss: 3.8770 - val_acc: 0.2289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc80659518>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second model (Medium hidden layers (4))\n",
    "model_two = Sequential()\n",
    "\n",
    "model_two.add(Dense(units = d, input_shape = train_x[0].shape))\n",
    "\n",
    "model_two.add(Dense(units = 500, activation = 'sigmoid'))\n",
    "model_two.add(Dense(units = 500, activation = 'sigmoid'))\n",
    "model_two.add(Dense(units = 500, activation = 'sigmoid'))\n",
    "model_two.add(Dense(units = 500, activation = 'sigmoid'))\n",
    "\n",
    "model_two.add(Dense(units = 5, activation = 'softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "model_two.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_two.summary()\n",
    "\n",
    "model_two.fit(train_x, train_y, batch_size = 200, epochs = 10, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 3454)              11933570  \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 500)               1727500   \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 14,415,075\n",
      "Trainable params: 14,415,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1561 samples, validate on 664 samples\n",
      "Epoch 1/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 5.5574 - acc: 0.3139 - val_loss: 1.7642 - val_acc: 0.3464\n",
      "Epoch 2/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 1.5443 - acc: 0.4023 - val_loss: 1.3191 - val_acc: 0.4111\n",
      "Epoch 3/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 1.0838 - acc: 0.5400 - val_loss: 1.0187 - val_acc: 0.5377\n",
      "Epoch 4/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.7622 - acc: 0.6931 - val_loss: 1.0769 - val_acc: 0.5919\n",
      "Epoch 5/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.4774 - acc: 0.8347 - val_loss: 1.1877 - val_acc: 0.6175\n",
      "Epoch 6/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.3385 - acc: 0.8969 - val_loss: 1.3037 - val_acc: 0.6702\n",
      "Epoch 7/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.2385 - acc: 0.9334 - val_loss: 1.1537 - val_acc: 0.6867\n",
      "Epoch 8/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.1607 - acc: 0.9571 - val_loss: 1.3199 - val_acc: 0.7033\n",
      "Epoch 9/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.1138 - acc: 0.9699 - val_loss: 1.3490 - val_acc: 0.6988\n",
      "Epoch 10/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0827 - acc: 0.9763 - val_loss: 1.3748 - val_acc: 0.7018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb371a9b38>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second model (Medium hidden layers (4))\n",
    "model_two = Sequential()\n",
    "\n",
    "model_two.add(Dense(units = d, input_shape = train_x[0].shape))\n",
    "\n",
    "model_two.add(Dense(units = 500, activation = 'tanh'))\n",
    "model_two.add(Dense(units = 500, activation = 'tanh'))\n",
    "model_two.add(Dense(units = 500, activation = 'tanh'))\n",
    "model_two.add(Dense(units = 500, activation = 'tanh'))\n",
    "\n",
    "model_two.add(Dense(units = 5, activation = 'softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "model_two.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_two.summary()\n",
    "\n",
    "model_two.fit(train_x, train_y, batch_size = 200, epochs = 10, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks (Second Model) with varying number of hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 3454)              11933570  \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1000)              3455000   \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 5)                 630       \n",
      "=================================================================\n",
      "Total params: 16,046,325\n",
      "Trainable params: 16,046,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1561 samples, validate on 664 samples\n",
      "Epoch 1/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 2.2552 - acc: 0.3434 - val_loss: 1.1364 - val_acc: 0.4955\n",
      "Epoch 2/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.7921 - acc: 0.7341 - val_loss: 1.2554 - val_acc: 0.6446\n",
      "Epoch 3/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.2496 - acc: 0.9398 - val_loss: 0.7206 - val_acc: 0.7033\n",
      "Epoch 4/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0834 - acc: 0.9865 - val_loss: 0.7703 - val_acc: 0.6928\n",
      "Epoch 5/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0433 - acc: 0.9917 - val_loss: 1.1407 - val_acc: 0.7289\n",
      "Epoch 6/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0139 - acc: 0.9981 - val_loss: 1.3566 - val_acc: 0.7078\n",
      "Epoch 7/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0183 - acc: 0.9974 - val_loss: 1.5008 - val_acc: 0.7334\n",
      "Epoch 8/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0360 - acc: 0.9923 - val_loss: 1.2452 - val_acc: 0.7169\n",
      "Epoch 9/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.0646 - acc: 0.9891 - val_loss: 1.6947 - val_acc: 0.7184\n",
      "Epoch 10/10\n",
      "1561/1561 [==============================] - 2s 1ms/step - loss: 0.1216 - acc: 0.9865 - val_loss: 2.3324 - val_acc: 0.6747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xcda44ea20>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second model (Medium hidden layers (4))\n",
    "model_two = Sequential()\n",
    "\n",
    "model_two.add(Dense(units = d, input_shape = train_x[0].shape))\n",
    "\n",
    "model_two.add(Dense(units = 1000, activation = 'relu'))\n",
    "model_two.add(Dense(units = 500, activation = 'relu'))\n",
    "model_two.add(Dense(units = 250, activation = 'relu'))\n",
    "model_two.add(Dense(units = 125, activation = 'relu'))\n",
    "\n",
    "model_two.add(Dense(units = 5, activation = 'softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "model_two.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_two.summary()\n",
    "\n",
    "model_two.fit(train_x, train_y, batch_size = 200, epochs = 10, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 3454)              11933570  \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2000)              6910000   \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 21,471,575\n",
      "Trainable params: 21,471,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1561 samples, validate on 664 samples\n",
      "Epoch 1/10\n",
      "1561/1561 [==============================] - 4s 3ms/step - loss: 2.9000 - acc: 0.2172 - val_loss: 1.5439 - val_acc: 0.2530\n",
      "Epoch 2/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 2.1525 - acc: 0.4222 - val_loss: 1.0861 - val_acc: 0.4563\n",
      "Epoch 3/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 1.2254 - acc: 0.7060 - val_loss: 0.8779 - val_acc: 0.5663\n",
      "Epoch 4/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 0.7977 - acc: 0.8463 - val_loss: 1.0814 - val_acc: 0.6822\n",
      "Epoch 5/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 0.5730 - acc: 0.9078 - val_loss: 1.1396 - val_acc: 0.6521\n",
      "Epoch 6/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 0.4588 - acc: 0.9468 - val_loss: 0.9222 - val_acc: 0.6898\n",
      "Epoch 7/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 0.3859 - acc: 0.9616 - val_loss: 1.0984 - val_acc: 0.7108\n",
      "Epoch 8/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 0.3707 - acc: 0.9699 - val_loss: 1.3559 - val_acc: 0.7184\n",
      "Epoch 9/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 0.3739 - acc: 0.9680 - val_loss: 1.4481 - val_acc: 0.7244\n",
      "Epoch 10/10\n",
      "1561/1561 [==============================] - 3s 2ms/step - loss: 0.4567 - acc: 0.9609 - val_loss: 1.7418 - val_acc: 0.6898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb38cc0e80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second model (Medium hidden layers (4))\n",
    "model_two = Sequential()\n",
    "\n",
    "model_two.add(Dense(units = d, input_shape = train_x[0].shape))\n",
    "\n",
    "model_two.add(Dense(units = 2000, activation = 'relu'))\n",
    "model_two.add(Dense(units = 1000, activation = 'relu'))\n",
    "model_two.add(Dense(units = 500, activation = 'relu'))\n",
    "model_two.add(Dense(units = 250, activation = 'relu'))\n",
    "\n",
    "model_two.add(Dense(units = 5, activation = 'softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "model_two.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_two.summary()\n",
    "\n",
    "model_two.fit(train_x, train_y, batch_size = 200, epochs = 10, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing the NN Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_range = np.arange(1, 11, 1)\n",
    "plt.plot(x_range, history.train_accuracy)\n",
    "plt.plot(x_range, history.test_accuracy)\n",
    "plt.title('Model 2 (with Batch Normalization)')\n",
    "plt.legend((\"Training\", \"Testing\"), loc=\"best\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
